{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "354ebecb",
   "metadata": {},
   "source": [
    "<h1>Model Development: Logistic Regression</h1>\n",
    "\n",
    "Source: https://github.com/cdaman123/Sentiment-Analysis-using-Logistic-Regression/blob/main/Sentiment_Analysis_LR.ipynb\n",
    "\n",
    "## Table of Contents<a name=\"TOC\"></a>\n",
    "\n",
    "1. [Splitting the Dataset Into Training and Testing Sets](#Section1)\n",
    "<br>First, separate the columns into dependent and independent variables (or features and labels). Then you split those variables into train and test sets.</br>\n",
    "\n",
    "2. [Feature Extraction](#Section2)\n",
    "<br>Includes document-term matirx (TF-IDF & BOW)</br>\n",
    "\n",
    "3. [Model Generation](#Section3)\n",
    "<br>Building SA Modelling using **Logistic Regression**</br>\n",
    "\n",
    "4. [Model Evaluation](#Section4)\n",
    "<br>Evaluate the Logistic Regression modelling based on performance metrics</br>\n",
    "\n",
    "5. [Visualization](#Section5)\n",
    "<br>Heatmpas and Stacked Bar Charts</br>\n",
    "\n",
    "To save the model, click [here](#Section10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab4b282",
   "metadata": {},
   "source": [
    "**Importing libraries & dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32cd2066",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import nltk\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94270d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Username</th>\n",
       "      <th>Cleaned_Tweets</th>\n",
       "      <th>Location</th>\n",
       "      <th>VADER_score</th>\n",
       "      <th>TextBlob_score</th>\n",
       "      <th>Harmonized_Score</th>\n",
       "      <th>Harmonized_Label</th>\n",
       "      <th>Risk_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27/1/2023 14:32</td>\n",
       "      <td>Don Dale</td>\n",
       "      <td>buying forget review first guy feel want comme...</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>0.6703</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>0.210150</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Low Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27/1/2023 19:04</td>\n",
       "      <td>Iliani</td>\n",
       "      <td>food security research going explode issue end...</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>0.5859</td>\n",
       "      <td>-0.181818</td>\n",
       "      <td>0.202041</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Low Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29/1/2023 8:28</td>\n",
       "      <td>Naim Zaini</td>\n",
       "      <td>context slaughtered food muslim consideration ...</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>0.8658</td>\n",
       "      <td>0.034722</td>\n",
       "      <td>0.450261</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Low Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29/1/2023 13:29</td>\n",
       "      <td>??</td>\n",
       "      <td>raise food price wet good expensive sorry guy</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>0.3818</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.140900</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Low Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30/1/2023 21:52</td>\n",
       "      <td>Alinosourawr</td>\n",
       "      <td>che restaurant sek send food x order food drin...</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>-0.8934</td>\n",
       "      <td>-0.433333</td>\n",
       "      <td>-0.663367</td>\n",
       "      <td>Strongly Negative</td>\n",
       "      <td>Severe Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21832</th>\n",
       "      <td>2023-03-30 23:45:13+00:00</td>\n",
       "      <td>Charrlygirl</td>\n",
       "      <td>worried prosecution team family also worried f...</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>-0.8360</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.418000</td>\n",
       "      <td>Mild Negative</td>\n",
       "      <td>Moderate Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21833</th>\n",
       "      <td>2023-03-30 23:49:23+00:00</td>\n",
       "      <td>angel19971102</td>\n",
       "      <td>love much clark must always worried bruce drea...</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>0.6939</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.546950</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Low Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21834</th>\n",
       "      <td>2023-03-30 23:55:01+00:00</td>\n",
       "      <td>firdyfire</td>\n",
       "      <td>industry player worried energy commission chie...</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>-0.0258</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.012900</td>\n",
       "      <td>Weakly Negative</td>\n",
       "      <td>Mild Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21835</th>\n",
       "      <td>2023-03-30 23:55:16+00:00</td>\n",
       "      <td>AhmadMuhyie</td>\n",
       "      <td>ah really weak faith fasting without real exam...</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>0.6222</td>\n",
       "      <td>0.239583</td>\n",
       "      <td>0.430892</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Low Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21836</th>\n",
       "      <td>2023-03-30 23:57:11+00:00</td>\n",
       "      <td>farhinsyirh</td>\n",
       "      <td>hate sin man know recorded video amazes contin...</td>\n",
       "      <td>Johore, Malaysia</td>\n",
       "      <td>-0.2167</td>\n",
       "      <td>-0.288889</td>\n",
       "      <td>-0.252794</td>\n",
       "      <td>Weakly Negative</td>\n",
       "      <td>Mild Risk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21837 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Datetime       Username   \n",
       "0                27/1/2023 14:32       Don Dale  \\\n",
       "1                27/1/2023 19:04         Iliani   \n",
       "2                 29/1/2023 8:28     Naim Zaini   \n",
       "3                29/1/2023 13:29             ??   \n",
       "4                30/1/2023 21:52   Alinosourawr   \n",
       "...                          ...            ...   \n",
       "21832  2023-03-30 23:45:13+00:00    Charrlygirl   \n",
       "21833  2023-03-30 23:49:23+00:00  angel19971102   \n",
       "21834  2023-03-30 23:55:01+00:00      firdyfire   \n",
       "21835  2023-03-30 23:55:16+00:00    AhmadMuhyie   \n",
       "21836  2023-03-30 23:57:11+00:00    farhinsyirh   \n",
       "\n",
       "                                          Cleaned_Tweets          Location   \n",
       "0      buying forget review first guy feel want comme...          Malaysia  \\\n",
       "1      food security research going explode issue end...          Malaysia   \n",
       "2      context slaughtered food muslim consideration ...          Malaysia   \n",
       "3          raise food price wet good expensive sorry guy          Malaysia   \n",
       "4      che restaurant sek send food x order food drin...          Malaysia   \n",
       "...                                                  ...               ...   \n",
       "21832  worried prosecution team family also worried f...          Malaysia   \n",
       "21833  love much clark must always worried bruce drea...          Malaysia   \n",
       "21834  industry player worried energy commission chie...          Malaysia   \n",
       "21835  ah really weak faith fasting without real exam...          Malaysia   \n",
       "21836  hate sin man know recorded video amazes contin...  Johore, Malaysia   \n",
       "\n",
       "       VADER_score  TextBlob_score  Harmonized_Score   Harmonized_Label   \n",
       "0           0.6703       -0.250000          0.210150           Positive  \\\n",
       "1           0.5859       -0.181818          0.202041           Positive   \n",
       "2           0.8658        0.034722          0.450261           Positive   \n",
       "3           0.3818       -0.100000          0.140900           Positive   \n",
       "4          -0.8934       -0.433333         -0.663367  Strongly Negative   \n",
       "...            ...             ...               ...                ...   \n",
       "21832      -0.8360        0.000000         -0.418000      Mild Negative   \n",
       "21833       0.6939        0.400000          0.546950           Positive   \n",
       "21834      -0.0258        0.000000         -0.012900    Weakly Negative   \n",
       "21835       0.6222        0.239583          0.430892           Positive   \n",
       "21836      -0.2167       -0.288889         -0.252794    Weakly Negative   \n",
       "\n",
       "          Risk_Label  \n",
       "0           Low Risk  \n",
       "1           Low Risk  \n",
       "2           Low Risk  \n",
       "3           Low Risk  \n",
       "4        Severe Risk  \n",
       "...              ...  \n",
       "21832  Moderate Risk  \n",
       "21833       Low Risk  \n",
       "21834      Mild Risk  \n",
       "21835       Low Risk  \n",
       "21836      Mild Risk  \n",
       "\n",
       "[21837 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load csv file containing tweets dataset (w/ sentiments)\n",
    "\n",
    "tweets_df = pd.read_csv(r\"C:\\Users\\LENOVO\\Documents\\Degree Life\\FYP Journey\\Dataset\\Sentiment Analysis\\V3 Harmonized [VADER & TextBlob]_All Keywords (Whole Malaysia).csv\")\n",
    "display(tweets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ed8c127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cleaned_Tweets</th>\n",
       "      <th>Harmonized_Score</th>\n",
       "      <th>Harmonized_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>buying forget review first guy feel want comme...</td>\n",
       "      <td>0.210150</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>food security research going explode issue end...</td>\n",
       "      <td>0.202041</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>context slaughtered food muslim consideration ...</td>\n",
       "      <td>0.450261</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>raise food price wet good expensive sorry guy</td>\n",
       "      <td>0.140900</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>che restaurant sek send food x order food drin...</td>\n",
       "      <td>-0.663367</td>\n",
       "      <td>Strongly Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21832</th>\n",
       "      <td>worried prosecution team family also worried f...</td>\n",
       "      <td>-0.418000</td>\n",
       "      <td>Mild Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21833</th>\n",
       "      <td>love much clark must always worried bruce drea...</td>\n",
       "      <td>0.546950</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21834</th>\n",
       "      <td>industry player worried energy commission chie...</td>\n",
       "      <td>-0.012900</td>\n",
       "      <td>Weakly Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21835</th>\n",
       "      <td>ah really weak faith fasting without real exam...</td>\n",
       "      <td>0.430892</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21836</th>\n",
       "      <td>hate sin man know recorded video amazes contin...</td>\n",
       "      <td>-0.252794</td>\n",
       "      <td>Weakly Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21837 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Cleaned_Tweets  Harmonized_Score   \n",
       "0      buying forget review first guy feel want comme...          0.210150  \\\n",
       "1      food security research going explode issue end...          0.202041   \n",
       "2      context slaughtered food muslim consideration ...          0.450261   \n",
       "3          raise food price wet good expensive sorry guy          0.140900   \n",
       "4      che restaurant sek send food x order food drin...         -0.663367   \n",
       "...                                                  ...               ...   \n",
       "21832  worried prosecution team family also worried f...         -0.418000   \n",
       "21833  love much clark must always worried bruce drea...          0.546950   \n",
       "21834  industry player worried energy commission chie...         -0.012900   \n",
       "21835  ah really weak faith fasting without real exam...          0.430892   \n",
       "21836  hate sin man know recorded video amazes contin...         -0.252794   \n",
       "\n",
       "        Harmonized_Label  \n",
       "0               Positive  \n",
       "1               Positive  \n",
       "2               Positive  \n",
       "3               Positive  \n",
       "4      Strongly Negative  \n",
       "...                  ...  \n",
       "21832      Mild Negative  \n",
       "21833           Positive  \n",
       "21834    Weakly Negative  \n",
       "21835           Positive  \n",
       "21836    Weakly Negative  \n",
       "\n",
       "[21837 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#drop irrelvant columns for modelling purposes\n",
    "#Irrelevant columns = \"Datetime\", \"Username\", \"Location\"\n",
    "new_df = tweets_df.drop(['Datetime', 'Username','Location'], axis=1)\n",
    "\n",
    "# Create a list of the column names in the desired order\n",
    "cols = ['Cleaned_Tweets', 'Harmonized_Score', 'Harmonized_Label']\n",
    "\n",
    "# Rearrange the columns in the dataset\n",
    "new_df = new_df[cols]\n",
    "\n",
    "display(new_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c68f20",
   "metadata": {},
   "source": [
    "## 1. Splitting the Dataset Into Training and Testing Sets<a name=\"Section1\"></a>\n",
    "\n",
    "<img src=\"https://editor.analyticsvidhya.com/uploads/63129111111.png\">\n",
    "\n",
    "<br>\n",
    "LabelEncoder() from sklearn.preprocessing is used to convert the labels (‘positive’, ‘negative’) into 1’s and 0’s respectively\n",
    "</br>\n",
    "\n",
    "The dataset is then split into 2 different train-test splits using train_test_split from sklearn.model_selection.\n",
    "\n",
    "1. 70:30\n",
    "2. 80:20\n",
    "\n",
    "Modified source code found from this website: https://www.analyticsvidhya.com/blog/2022/03/building-naive-bayes-classifier-from-scratch-to-perform-sentiment-analysis/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "434dacde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the features and labels\n",
    "features = new_df['Cleaned_Tweets'].values\n",
    "labels = new_df['Harmonized_Label'].values\n",
    "\n",
    "# Use LabelEncoder to convert labels to numerical values\n",
    "# Positive [1] OR Negative [0]\n",
    "encoder = LabelEncoder()\n",
    "encoded_labels = encoder.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31b273c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17469,), (4368,), (17469,), (4368,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "# Remember to modify test size each time you're trying to run a new model!!\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, encoded_labels, \n",
    "                                                                            test_size=0.2, random_state=42)\n",
    "train_features.shape, test_features.shape, train_labels.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41ec95bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cleaned_Tweets</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>beginning crazy hungry</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>location wisma pika place dive wonderful indon...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>soo busy working forgot eat hungry lazy tired ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>want eat hungry</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sorry narrow photo hunger smpe home eat eat co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17464</th>\n",
       "      <td>power hungry selfish narcissistic unpatriotic ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17465</th>\n",
       "      <td>depending deed think read quran ramadan cake b...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17466</th>\n",
       "      <td>yummy feeling hungry back</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17467</th>\n",
       "      <td>weight worried pr</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17468</th>\n",
       "      <td>keeping hunger drive inside clip podcast tm cy...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17469 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Cleaned_Tweets  Sentiment\n",
       "0                                 beginning crazy hungry          0\n",
       "1      location wisma pika place dive wonderful indon...          1\n",
       "2      soo busy working forgot eat hungry lazy tired ...          3\n",
       "3                                        want eat hungry          1\n",
       "4      sorry narrow photo hunger smpe home eat eat co...          0\n",
       "...                                                  ...        ...\n",
       "17464  power hungry selfish narcissistic unpatriotic ...          1\n",
       "17465  depending deed think read quran ramadan cake b...          3\n",
       "17466                          yummy feeling hungry back          1\n",
       "17467                                  weight worried pr          3\n",
       "17468  keeping hunger drive inside clip podcast tm cy...          3\n",
       "\n",
       "[17469 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert train_features and train_labels back to Pandas DataFrames\n",
    "train_data = pd.DataFrame({'Cleaned_Tweets': train_features, 'Sentiment': train_labels})\n",
    "#train_data = pd.concat([train_features.reset_index(drop=True), train_labels.reset_index(drop=True)], axis=1)\n",
    "display(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d924568c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cleaned_Tweets</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hungry cook</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>want take responsibility accnt endo getting ne...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>please relax worried know love work please lov...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>annual agenda pansos hurry came path individua...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>okay csb worried growing old ouch inner tita g...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4363</th>\n",
       "      <td>km step kcal gpp today hungry tomorrow let tig...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4364</th>\n",
       "      <td>japan germany many military germany also appet...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4365</th>\n",
       "      <td>nice look yummy art wow make hungry xd</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4366</th>\n",
       "      <td>haha sasha ok bit worried cousin celebrates ju...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4367</th>\n",
       "      <td>hour scrolling khairul aming recipe hungry vid...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4368 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Cleaned_Tweets  Sentiment\n",
       "0                                           hungry cook          1\n",
       "1     want take responsibility accnt endo getting ne...          1\n",
       "2     please relax worried know love work please lov...          1\n",
       "3     annual agenda pansos hurry came path individua...          0\n",
       "4     okay csb worried growing old ouch inner tita g...          3\n",
       "...                                                 ...        ...\n",
       "4363  km step kcal gpp today hungry tomorrow let tig...          1\n",
       "4364  japan germany many military germany also appet...          3\n",
       "4365             nice look yummy art wow make hungry xd          1\n",
       "4366  haha sasha ok bit worried cousin celebrates ju...          1\n",
       "4367  hour scrolling khairul aming recipe hungry vid...          1\n",
       "\n",
       "[4368 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert test_features and test_labels back to Pandas DataFrames\n",
    "test_data = pd.DataFrame({'Cleaned_Tweets': test_features, 'Sentiment': test_labels})\n",
    "display(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833c2333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the training set to a CSV file\n",
    "train_data.to_csv('(70-30) TextBlob train_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe1c5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the training set to a CSV file\n",
    "test_data.to_csv('(70-30) TextBlob test_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83415783",
   "metadata": {},
   "source": [
    "<h2> To check if the dataset is balanced </h2>\n",
    "\n",
    "Source: https://towardsdatascience.com/fine-grained-sentiment-analysis-in-python-part-1-2697bb111ed4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e950835",
   "metadata": {},
   "source": [
    "## TextBlob/VADER Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c3a8c8",
   "metadata": {},
   "source": [
    "**Train data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893c5e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "ax = train_data['Sentiment'].value_counts(sort=False).plot(kind='barh')\n",
    "ax.set_xlabel(\"Number of Samples in Training Set\")\n",
    "ax.set_ylabel(\"Label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a94aa3",
   "metadata": {},
   "source": [
    "**Test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed84867a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "ax = test_data['Sentiment'].value_counts(sort=False).plot(kind='barh')\n",
    "ax.set_xlabel(\"Number of Samples in Testing Set\")\n",
    "ax.set_ylabel(\"Label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042a4380",
   "metadata": {},
   "source": [
    "## Harmonized Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bd0add",
   "metadata": {},
   "source": [
    "For Harmonized Sentiments dataset, the following sentiment labels represented as follows:\n",
    "\n",
    "0 - Positive\n",
    "\n",
    "1 - Weakly Negative\n",
    "\n",
    "2 - Mild Negative\n",
    "\n",
    "3 - Strongly Negative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe1ae93",
   "metadata": {},
   "source": [
    "**Train data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556a580c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the colors for each sentiment label\n",
    "colors = ['green', 'yellow', 'orange', 'red']\n",
    "\n",
    "# Plot the sentiment label counts with corresponding colors\n",
    "ax = train_data['Sentiment'].value_counts(sort=False).plot(kind='barh', color=colors)\n",
    "\n",
    "ax.set_xlabel(\"Number of Samples in Training Set\")\n",
    "ax.set_ylabel(\"Label\")\n",
    "\n",
    "# Add a legend for the colors\n",
    "legend_labels = ['Low FI Risk', 'Mild FI Risk', 'Moderate FI Risk', 'Severe FI Risk']\n",
    "legend_handles = [plt.Rectangle((0, 0), 1, 1, color=color) for color in colors]\n",
    "ax.legend(legend_handles, legend_labels)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42850846",
   "metadata": {},
   "source": [
    "**Test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f13c978",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the colors for each sentiment label\n",
    "colors = ['green', 'yellow', 'orange', 'red']\n",
    "\n",
    "# Plot the sentiment label counts with corresponding colors\n",
    "ax = train_data['Sentiment'].value_counts(sort=False).plot(kind='barh', color=colors)\n",
    "\n",
    "ax.set_xlabel(\"Number of Samples in Training Set\")\n",
    "ax.set_ylabel(\"Label\")\n",
    "\n",
    "# Add a legend for the colors\n",
    "legend_labels = ['Low FI Risk', 'Mild FI Risk', 'Moderate FI Risk', 'Severe FI Risk']\n",
    "legend_handles = [plt.Rectangle((0, 0), 1, 1, color=color) for color in colors]\n",
    "ax.legend(legend_handles, legend_labels)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef060a51",
   "metadata": {},
   "source": [
    "## 2. Feature Extraction<a name=\"Section2\"></a>\n",
    "Using both TF-IDF and BOW for feature extraction\n",
    "\n",
    "Try to do it seperately for each modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543e7291",
   "metadata": {},
   "source": [
    "**A. TF-IDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0e2364f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17469, 23457), (4368, 23457))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace NaN values with an empty string\n",
    "train_features = np.where(pd.isnull(train_features), '', train_features)\n",
    "\n",
    "# Create an instance of TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()  # For TF-IDF\n",
    "\n",
    "# Fit the vectorizer on the training data and transform the training features\n",
    "train_features_vectorized = vectorizer.fit_transform(train_features)\n",
    "\n",
    "# Transform the testing features using the trained vectorizer\n",
    "test_features_vectorized = vectorizer.transform(test_features)\n",
    "\n",
    "train_features_vectorized.shape, test_features_vectorized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05614617",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features:\n",
      "         aa  aaa  aaaa  aaaaa  aaaaaaa  aaaaaaaaaaaaa  aaaaaaaaaaaaaahhhhh   \n",
      "0      0.0  0.0   0.0    0.0      0.0            0.0                  0.0  \\\n",
      "1      0.0  0.0   0.0    0.0      0.0            0.0                  0.0   \n",
      "2      0.0  0.0   0.0    0.0      0.0            0.0                  0.0   \n",
      "3      0.0  0.0   0.0    0.0      0.0            0.0                  0.0   \n",
      "4      0.0  0.0   0.0    0.0      0.0            0.0                  0.0   \n",
      "...    ...  ...   ...    ...      ...            ...                  ...   \n",
      "17464  0.0  0.0   0.0    0.0      0.0            0.0                  0.0   \n",
      "17465  0.0  0.0   0.0    0.0      0.0            0.0                  0.0   \n",
      "17466  0.0  0.0   0.0    0.0      0.0            0.0                  0.0   \n",
      "17467  0.0  0.0   0.0    0.0      0.0            0.0                  0.0   \n",
      "17468  0.0  0.0   0.0    0.0      0.0            0.0                  0.0   \n",
      "\n",
      "       aaaaaaaaaaarrrrrrrrr  aaarghhh  aaengai  ...  zuhur  zuiko  zul   \n",
      "0                       0.0       0.0      0.0  ...    0.0    0.0  0.0  \\\n",
      "1                       0.0       0.0      0.0  ...    0.0    0.0  0.0   \n",
      "2                       0.0       0.0      0.0  ...    0.0    0.0  0.0   \n",
      "3                       0.0       0.0      0.0  ...    0.0    0.0  0.0   \n",
      "4                       0.0       0.0      0.0  ...    0.0    0.0  0.0   \n",
      "...                     ...       ...      ...  ...    ...    ...  ...   \n",
      "17464                   0.0       0.0      0.0  ...    0.0    0.0  0.0   \n",
      "17465                   0.0       0.0      0.0  ...    0.0    0.0  0.0   \n",
      "17466                   0.0       0.0      0.0  ...    0.0    0.0  0.0   \n",
      "17467                   0.0       0.0      0.0  ...    0.0    0.0  0.0   \n",
      "17468                   0.0       0.0      0.0  ...    0.0    0.0  0.0   \n",
      "\n",
      "       zulkifli  zumba  zuzu   zz  zzzz  zzzzs  zzzzz  \n",
      "0           0.0    0.0   0.0  0.0   0.0    0.0    0.0  \n",
      "1           0.0    0.0   0.0  0.0   0.0    0.0    0.0  \n",
      "2           0.0    0.0   0.0  0.0   0.0    0.0    0.0  \n",
      "3           0.0    0.0   0.0  0.0   0.0    0.0    0.0  \n",
      "4           0.0    0.0   0.0  0.0   0.0    0.0    0.0  \n",
      "...         ...    ...   ...  ...   ...    ...    ...  \n",
      "17464       0.0    0.0   0.0  0.0   0.0    0.0    0.0  \n",
      "17465       0.0    0.0   0.0  0.0   0.0    0.0    0.0  \n",
      "17466       0.0    0.0   0.0  0.0   0.0    0.0    0.0  \n",
      "17467       0.0    0.0   0.0  0.0   0.0    0.0    0.0  \n",
      "17468       0.0    0.0   0.0  0.0   0.0    0.0    0.0  \n",
      "\n",
      "[17469 rows x 23457 columns]\n",
      "Testing Features:\n",
      "        aa  aaa  aaaa  aaaaa  aaaaaaa  aaaaaaaaaaaaa  aaaaaaaaaaaaaahhhhh   \n",
      "0     0.0  0.0   0.0    0.0      0.0            0.0                  0.0  \\\n",
      "1     0.0  0.0   0.0    0.0      0.0            0.0                  0.0   \n",
      "2     0.0  0.0   0.0    0.0      0.0            0.0                  0.0   \n",
      "3     0.0  0.0   0.0    0.0      0.0            0.0                  0.0   \n",
      "4     0.0  0.0   0.0    0.0      0.0            0.0                  0.0   \n",
      "...   ...  ...   ...    ...      ...            ...                  ...   \n",
      "4363  0.0  0.0   0.0    0.0      0.0            0.0                  0.0   \n",
      "4364  0.0  0.0   0.0    0.0      0.0            0.0                  0.0   \n",
      "4365  0.0  0.0   0.0    0.0      0.0            0.0                  0.0   \n",
      "4366  0.0  0.0   0.0    0.0      0.0            0.0                  0.0   \n",
      "4367  0.0  0.0   0.0    0.0      0.0            0.0                  0.0   \n",
      "\n",
      "      aaaaaaaaaaarrrrrrrrr  aaarghhh  aaengai  ...  zuhur  zuiko  zul   \n",
      "0                      0.0       0.0      0.0  ...    0.0    0.0  0.0  \\\n",
      "1                      0.0       0.0      0.0  ...    0.0    0.0  0.0   \n",
      "2                      0.0       0.0      0.0  ...    0.0    0.0  0.0   \n",
      "3                      0.0       0.0      0.0  ...    0.0    0.0  0.0   \n",
      "4                      0.0       0.0      0.0  ...    0.0    0.0  0.0   \n",
      "...                    ...       ...      ...  ...    ...    ...  ...   \n",
      "4363                   0.0       0.0      0.0  ...    0.0    0.0  0.0   \n",
      "4364                   0.0       0.0      0.0  ...    0.0    0.0  0.0   \n",
      "4365                   0.0       0.0      0.0  ...    0.0    0.0  0.0   \n",
      "4366                   0.0       0.0      0.0  ...    0.0    0.0  0.0   \n",
      "4367                   0.0       0.0      0.0  ...    0.0    0.0  0.0   \n",
      "\n",
      "      zulkifli  zumba  zuzu   zz  zzzz  zzzzs  zzzzz  \n",
      "0          0.0    0.0   0.0  0.0   0.0    0.0    0.0  \n",
      "1          0.0    0.0   0.0  0.0   0.0    0.0    0.0  \n",
      "2          0.0    0.0   0.0  0.0   0.0    0.0    0.0  \n",
      "3          0.0    0.0   0.0  0.0   0.0    0.0    0.0  \n",
      "4          0.0    0.0   0.0  0.0   0.0    0.0    0.0  \n",
      "...        ...    ...   ...  ...   ...    ...    ...  \n",
      "4363       0.0    0.0   0.0  0.0   0.0    0.0    0.0  \n",
      "4364       0.0    0.0   0.0  0.0   0.0    0.0    0.0  \n",
      "4365       0.0    0.0   0.0  0.0   0.0    0.0    0.0  \n",
      "4366       0.0    0.0   0.0  0.0   0.0    0.0    0.0  \n",
      "4367       0.0    0.0   0.0  0.0   0.0    0.0    0.0  \n",
      "\n",
      "[4368 rows x 23457 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert the sparse matrix to a dense matrix and create a DataFrame\n",
    "train_features_df = pd.DataFrame(train_features_vectorized.toarray(), columns=vectorizer.get_feature_names())\n",
    "test_features_df = pd.DataFrame(test_features_vectorized.toarray(), columns=vectorizer.get_feature_names())\n",
    "\n",
    "# Display the feature vectors\n",
    "print(\"Training Features:\\n\", train_features_df)\n",
    "print(\"Testing Features:\\n\", test_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1da07b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the train_features vectors to CSV files\n",
    "train_features_df.to_csv('TF-IDF (70-30)- Harmonized train_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48d766e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the test_features vectors to CSV files\n",
    "test_features_df.to_csv('TF-IDF (70-30)- Harmonized test_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8427f730",
   "metadata": {},
   "source": [
    "**B. BOW**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182d92c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN values with an empty string\n",
    "train_features = np.where(pd.isnull(train_features), '', train_features)\n",
    "\n",
    "# Create an instance of CountVectorizer\n",
    "vectorizer = CountVectorizer()  # For BoW\n",
    "\n",
    "# Fit the vectorizer on the training data and transform the training features\n",
    "train_features_vectorized = vectorizer.fit_transform(train_features)\n",
    "\n",
    "# Transform the testing features using the trained vectorizer\n",
    "test_features_vectorized = vectorizer.transform(test_features)\n",
    "\n",
    "train_features_vectorized.shape, test_features_vectorized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41acbb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the sparse matrix to a dense matrix and create a DataFrame\n",
    "train_features_df = pd.DataFrame(train_features_vectorized.toarray(), columns=vectorizer.get_feature_names())\n",
    "test_features_df = pd.DataFrame(test_features_vectorized.toarray(), columns=vectorizer.get_feature_names())\n",
    "\n",
    "# Display the feature vectors\n",
    "print(\"Training Features:\\n\", train_features_df)\n",
    "print(\"Testing Features:\\n\", test_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea425d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the train_features vectors to CSV files\n",
    "train_features_df.to_csv('BOW (70-30)- Harmonized train_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de514322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the test_features vectors to CSV files\n",
    "test_features_df.to_csv('BOW (70-30)- Harmonized test_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d582638a",
   "metadata": {},
   "source": [
    "## 3. Model Generation<a name=\"Section3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5005fac",
   "metadata": {},
   "source": [
    "## 3.1 Train model using Logistic Regression\n",
    "Logistic regression takes a regular linear regression, and applies a sigmoid to the output of the linear regression.\n",
    "\n",
    "\n",
    "How to train a LR classifier?\n",
    "- Calculate sigmoid function\n",
    "- Gradient Descent\n",
    "\n",
    "Approach:\n",
    "1. [From Scratch](#Section6)\n",
    "<br>Using sigmoid, cost function & graident descent</br>\n",
    "\n",
    "2. [Built in Package](#Section7) - I used this one to build my SA model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35a5944",
   "metadata": {},
   "source": [
    "### Approach 1: From Scratch<a name=\"Section6\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f023899c",
   "metadata": {
    "id": "oRJzLum7S0FA"
   },
   "source": [
    "### Part 1.1: Sigmoid\n",
    "We will learn to use logistic regression for text classification. \n",
    "* The sigmoid function is defined as: \n",
    "\n",
    "$$ h(z) = \\frac{1}{1+\\exp^{-z}} \\tag{1}$$\n",
    "\n",
    "It maps the input 'z' to a value that ranges between 0 and 1, and so it can be treated as a probability. \n",
    "\n",
    "![alt](https://raw.githubusercontent.com/cdaman123/Sentiment-Analysis-using-Logistic-Regression/main/sigmoid_plot.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cdd4ab",
   "metadata": {},
   "source": [
    "**Sigmoid Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a996c472",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z): \n",
    "    '''\n",
    "    Input:\n",
    "        z: is the input (can be a scalar or an array)\n",
    "    Output:\n",
    "        h: the sigmoid of z\n",
    "    '''\n",
    "    # calculate the sigmoid of z\n",
    "    h = 1/(1+np.exp(-1*z))\n",
    "        \n",
    "    return h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47c3cb0",
   "metadata": {},
   "source": [
    "**Cost Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c422985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost function\n",
    "def compute_cost(X, y, theta):\n",
    "    m = len(y)\n",
    "    h = sigmoid(np.dot(X, theta))\n",
    "    cost = (-1/m) * np.sum(y * np.log(h) + (1-y) * np.log(1-h))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d518a1",
   "metadata": {},
   "source": [
    "### Approach 2: Built in Package<a name=\"Section7\"></a>\n",
    "\n",
    "Built-in package found in scikit-learn library\n",
    "\n",
    "Using a multi-class approach = Multinomial Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0506eccf",
   "metadata": {},
   "source": [
    "**Training the Logistic Regression Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5225baaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create an instance of Multinomial Logistic Regression\n",
    "logreg = LogisticRegression(multi_class='multinomial', solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4e27b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 8.068827867507935 seconds\n",
      "{'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Train a Multinomial LR model on the training data\n",
    "start_time = time.time()\n",
    "logreg.fit(train_features_vectorized, train_labels)\n",
    "end_time = time.time()\n",
    "\n",
    "# Print the runtime of training the classifier\n",
    "print(f\"Training time: {end_time - start_time} seconds\")\n",
    "print(logreg.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae79a6b",
   "metadata": {},
   "source": [
    "**Predict labels of test data**\n",
    "<br>\n",
    "Use the print() function to display the test_predictions array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "083445b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction time: 0.0024051666259765625 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['Positive', 'Positive', 'Positive', ..., 'Positive', 'Positive',\n",
       "       'Positive'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a list of the sentiment labels\n",
    "sentiment_labels = ['Positive', 'Negative']\n",
    "\n",
    "# Predict the labels of the test data\n",
    "start_time = time.time()\n",
    "test_predictions = logreg.predict(test_features_vectorized)\n",
    "end_time = time.time()\n",
    "\n",
    "# Print the runtime of predicting the labels\n",
    "print(f\"Prediction time: {end_time - start_time} seconds\")\n",
    "\n",
    "# Convert the numeric labels back to sentiment labels\n",
    "actual_sentiments = encoder.inverse_transform(test_labels)\n",
    "predicted_sentiments = encoder.inverse_transform(test_predictions)\n",
    "\n",
    "# Print the predicted labels\n",
    "display(test_predictions, predicted_sentiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d532ced2",
   "metadata": {},
   "source": [
    "**Print results of predicted labels using DataFrame**\n",
    "\n",
    "Create a new DataFrame that combines the test data with the predicted labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce641cde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>actual_sentiment</th>\n",
       "      <th>predicted_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hungry cook</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>want take responsibility accnt endo getting ne...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>please relax worried know love work please lov...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>annual agenda pansos hurry came path individua...</td>\n",
       "      <td>Mild Negative</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>okay csb worried growing old ouch inner tita g...</td>\n",
       "      <td>Weakly Negative</td>\n",
       "      <td>Weakly Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4363</th>\n",
       "      <td>km step kcal gpp today hungry tomorrow let tig...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4364</th>\n",
       "      <td>japan germany many military germany also appet...</td>\n",
       "      <td>Weakly Negative</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4365</th>\n",
       "      <td>nice look yummy art wow make hungry xd</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4366</th>\n",
       "      <td>haha sasha ok bit worried cousin celebrates ju...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4367</th>\n",
       "      <td>hour scrolling khairul aming recipe hungry vid...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4368 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text actual_sentiment   \n",
       "0                                           hungry cook         Positive  \\\n",
       "1     want take responsibility accnt endo getting ne...         Positive   \n",
       "2     please relax worried know love work please lov...         Positive   \n",
       "3     annual agenda pansos hurry came path individua...    Mild Negative   \n",
       "4     okay csb worried growing old ouch inner tita g...  Weakly Negative   \n",
       "...                                                 ...              ...   \n",
       "4363  km step kcal gpp today hungry tomorrow let tig...         Positive   \n",
       "4364  japan germany many military germany also appet...  Weakly Negative   \n",
       "4365             nice look yummy art wow make hungry xd         Positive   \n",
       "4366  haha sasha ok bit worried cousin celebrates ju...         Positive   \n",
       "4367  hour scrolling khairul aming recipe hungry vid...         Positive   \n",
       "\n",
       "     predicted_sentiment  \n",
       "0               Positive  \n",
       "1               Positive  \n",
       "2               Positive  \n",
       "3               Positive  \n",
       "4        Weakly Negative  \n",
       "...                  ...  \n",
       "4363            Positive  \n",
       "4364            Positive  \n",
       "4365            Positive  \n",
       "4366            Positive  \n",
       "4367            Positive  \n",
       "\n",
       "[4368 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a DataFrame with the test data and predicted labels\n",
    "results_df = pd.DataFrame({'Text': test_data['Cleaned_Tweets'], 'actual_sentiment': actual_sentiments, \n",
    "                           'predicted_sentiment': predicted_sentiments})\n",
    "\n",
    "# Print the DataFrame\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00df53c",
   "metadata": {},
   "source": [
    "**For Harmonized**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f615386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>actual_sentiment</th>\n",
       "      <th>predicted_sentiment</th>\n",
       "      <th>actual_risk</th>\n",
       "      <th>predicted_risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hungry cook</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Low Risk</td>\n",
       "      <td>Low Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>want take responsibility accnt endo getting ne...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Low Risk</td>\n",
       "      <td>Low Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>please relax worried know love work please lov...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Low Risk</td>\n",
       "      <td>Low Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>annual agenda pansos hurry came path individua...</td>\n",
       "      <td>Mild Negative</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Moderate Risk</td>\n",
       "      <td>Low Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>okay csb worried growing old ouch inner tita g...</td>\n",
       "      <td>Weakly Negative</td>\n",
       "      <td>Weakly Negative</td>\n",
       "      <td>Mild Risk</td>\n",
       "      <td>Mild Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4363</th>\n",
       "      <td>km step kcal gpp today hungry tomorrow let tig...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Low Risk</td>\n",
       "      <td>Low Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4364</th>\n",
       "      <td>japan germany many military germany also appet...</td>\n",
       "      <td>Weakly Negative</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Mild Risk</td>\n",
       "      <td>Low Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4365</th>\n",
       "      <td>nice look yummy art wow make hungry xd</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Low Risk</td>\n",
       "      <td>Low Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4366</th>\n",
       "      <td>haha sasha ok bit worried cousin celebrates ju...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Low Risk</td>\n",
       "      <td>Low Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4367</th>\n",
       "      <td>hour scrolling khairul aming recipe hungry vid...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Low Risk</td>\n",
       "      <td>Low Risk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4368 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text actual_sentiment   \n",
       "0                                           hungry cook         Positive  \\\n",
       "1     want take responsibility accnt endo getting ne...         Positive   \n",
       "2     please relax worried know love work please lov...         Positive   \n",
       "3     annual agenda pansos hurry came path individua...    Mild Negative   \n",
       "4     okay csb worried growing old ouch inner tita g...  Weakly Negative   \n",
       "...                                                 ...              ...   \n",
       "4363  km step kcal gpp today hungry tomorrow let tig...         Positive   \n",
       "4364  japan germany many military germany also appet...  Weakly Negative   \n",
       "4365             nice look yummy art wow make hungry xd         Positive   \n",
       "4366  haha sasha ok bit worried cousin celebrates ju...         Positive   \n",
       "4367  hour scrolling khairul aming recipe hungry vid...         Positive   \n",
       "\n",
       "     predicted_sentiment    actual_risk predicted_risk  \n",
       "0               Positive       Low Risk       Low Risk  \n",
       "1               Positive       Low Risk       Low Risk  \n",
       "2               Positive       Low Risk       Low Risk  \n",
       "3               Positive  Moderate Risk       Low Risk  \n",
       "4        Weakly Negative      Mild Risk      Mild Risk  \n",
       "...                  ...            ...            ...  \n",
       "4363            Positive       Low Risk       Low Risk  \n",
       "4364            Positive      Mild Risk       Low Risk  \n",
       "4365            Positive       Low Risk       Low Risk  \n",
       "4366            Positive       Low Risk       Low Risk  \n",
       "4367            Positive       Low Risk       Low Risk  \n",
       "\n",
       "[4368 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a dictionary to map sentiment labels to risk labels\n",
    "sentiment_labels = ['Positive', 'Weakly Negative', 'Mild Negative', 'Strongly Negative']\n",
    "risk_labels = ['Low Risk', 'Mild Risk', 'Moderate Risk', 'Severe Risk']\n",
    "label_mapping = {sentiment_labels[i]: risk_labels[i] for i in range(len(sentiment_labels))}\n",
    "\n",
    "# Apply reassignment to the actual and predicted sentiment labels\n",
    "results_df['actual_risk'] = results_df['actual_sentiment'].map(label_mapping)\n",
    "results_df['predicted_risk'] = results_df['predicted_sentiment'].map(label_mapping)\n",
    "\n",
    "# Print the dataframe\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fe18b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save results into CSV file\n",
    "results_df.to_csv('MLR_BOW (80-20)- Initial Model Evaluation [Harmonized].csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bbe444",
   "metadata": {},
   "source": [
    "## Pickling the Model<a name=\"Section14\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fd7974",
   "metadata": {},
   "source": [
    "If you still want to see the full output of the classifier object, you can try using the pickle module to save the classifier object to a file and then load it back into memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22a763b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the classifier object to a file\n",
    "with open('logreg (Harmonized_BOW - 80-20).pkl', 'wb') as file:\n",
    "    pickle.dump(logreg, file)\n",
    "\n",
    "# Print the classifier object\n",
    "print(logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20341fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the classifier object from the file\n",
    "with open('logreg (TF-IDF - 70-30).pkl', 'rb') as file:\n",
    "    nb_classifier = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c4894d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In case you wanna use the loaded classifier model from file\n",
    "# Use this code to perform prediction\n",
    "predictions = loaded_model.predict(new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91112225",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation<a name=\"Section4\"></a>\n",
    "<br></br>\n",
    "**A. Evaluation Metrics:**\n",
    "\n",
    "1. Accuracy\n",
    "2. Precision\n",
    "3. F1 Score - Due to an imbalance classes, F1 score was metric was used </br>\n",
    "4. Recall\n",
    "\n",
    "**B. K-Fold Cross Validation**\n",
    "\n",
    "Using k-fold (k = 10)\n",
    "<br></br>\n",
    "Part of code retrieved from here:\n",
    "https://github.com/ThinamXx/Twitter..Sentiment..Analysis/blob/master/Twitter%20Sentiment%20Analysis.ipynb\n",
    "\n",
    "**C. Hypertuning Model**\n",
    "\n",
    "**D. Predicting Sentiment of New Text Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b001a1f",
   "metadata": {},
   "source": [
    "<h2> A. Evaluation Metrics </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff30ff4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using the fitted model to make predictions on testing data\n",
    "# Predict the labels of the test data\n",
    "test_predictions = logreg.predict(test_features_vectorized)\n",
    "\n",
    "# Print the predicted labels\n",
    "print(test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a79e44",
   "metadata": {},
   "source": [
    "**Checking the accuracy in Testing Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94876fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the performance of Logistic Regression classifier\n",
    "\n",
    "print(f\"Model evaluation on Testing Data:\\n {confusion_matrix(test_labels, test_predictions)}\")\n",
    "print(f\"Classification Report:\\n {classification_report(test_labels, test_predictions)}\")\n",
    "print(f\"Testing accuracy:\\n {accuracy_score(test_labels, test_predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5027b939",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(test_labels, test_predictions)\n",
    "\n",
    "# Calculate the precision of the classifier\n",
    "precision = precision_score(test_labels, test_predictions, average='weighted')\n",
    "\n",
    "# Calculate the recall of the classifier\n",
    "recall = recall_score(test_labels, test_predictions, average='weighted')\n",
    "\n",
    "# Calculate the F1 score of the classifier\n",
    "f1 = f1_score(test_labels, test_predictions, average='weighted')\n",
    "\n",
    "# Calculate the confusion matrix of the classifier\n",
    "confusion_mat = confusion_matrix(test_labels, test_predictions)\n",
    "\n",
    "# Define the labels for the confusion matrix\n",
    "labels = ['True Negative (TN)', 'False Positive (FP)', 'False Negative (FN)', 'True Positive (TP)']\n",
    "\n",
    "# Create a new confusion matrix with the labels\n",
    "confusion_mat_labeled = np.empty((2,2), dtype=int)\n",
    "confusion_mat_labeled[0,0] = confusion_mat[0,0] # True Negative\n",
    "confusion_mat_labeled[0,1] = confusion_mat[0,1] # False Positive\n",
    "confusion_mat_labeled[1,0] = confusion_mat[1,0] # False Negative\n",
    "confusion_mat_labeled[1,1] = confusion_mat[1,1] # True Positive\n",
    "\n",
    "# Create a DataFrame with the confusion matrix and labels\n",
    "confusion_df = pd.DataFrame(confusion_mat_labeled, index=labels[:2], columns=labels[2:])\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Evaluation Metrics:\")\n",
    "print(\"Accuracy:\", accuracy * 100, \"%\")\n",
    "print(\"Precision:\", precision * 100, \"%\")\n",
    "print(\"Recall:\", recall * 100, \"%\")\n",
    "print(\"F1 Score:\", f1 * 100, \"%\")\n",
    "display(\"Confusion Matrix:\", confusion_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6273b0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store the evaluation metrics\n",
    "evaluation_results = {\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "    'Score': [accuracy, precision, recall, f1]\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the evaluation results\n",
    "df_evaluation = pd.DataFrame(evaluation_results)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix\n",
    "confusion_df = pd.DataFrame(confusion_mat, columns=['False Negative', 'False Positive'], index=['True Negative', 'True Positive'])\n",
    "\n",
    "# Concatenate the evaluation DataFrame and confusion DataFrame\n",
    "results_df = pd.concat([df_evaluation, confusion_df], axis=0)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "results_df.to_csv('[Harmonized] MLR TF-IDF (80-20) Initial Predict Labelling Model_Evaluation.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8979b313",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Harmonized Sentiment Dataset\n",
    "# Create a dictionary to store the evaluation metrics\n",
    "metrics_dict = {\n",
    "    'Accuracy': [accuracy],\n",
    "    'Precision': [precision],\n",
    "    'Recall': [recall],\n",
    "    'F1 Score': [f1]\n",
    "}\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "metrics_df = pd.DataFrame(metrics_dict)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix\n",
    "class_labels = ['Label 1', 'Label 2', 'Label 3', 'Label 4']\n",
    "confusion_df = pd.DataFrame(confusion_mat, columns=class_labels, index=class_labels)\n",
    "\n",
    "# Create a Pandas Excel writer using the 'xlsxwriter' engine\n",
    "writer = pd.ExcelWriter('[Harmonized] MLR TF-IDF (80-20) Initial Predict Labelling Model_Evaluation.xlsx', engine='xlsxwriter')\n",
    "\n",
    "# Write the metrics DataFrame to a sheet named 'Metrics'\n",
    "metrics_df.to_excel(writer, sheet_name='Metrics', index=False)\n",
    "\n",
    "# Write the confusion matrix DataFrame to a sheet named 'Confusion Matrix'\n",
    "confusion_df.to_excel(writer, sheet_name='Confusion Matrix', index=True)\n",
    "\n",
    "# Save the Excel file\n",
    "writer.save()\n",
    "\n",
    "# Print a confirmation message\n",
    "print(\"[Harmonized] MLR TF-IDF (80-20) Initial Predict Labelling Model_Evaluation.xlsx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e2990d",
   "metadata": {},
   "source": [
    "**Error Analysis**\n",
    "\n",
    "In this part, we will see some tweets that your model missclassified. Why do we think the misclassifications happened? Were there any assumptions made by the naive bayes model?\n",
    "\n",
    "Source:\n",
    "<br>\n",
    "https://github.com/cdaman123/Sentiment-Analysis-using-Naive-Bayes/blob/main/Sentiment_Analysis_NB.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3c4306",
   "metadata": {},
   "source": [
    "<h3>ROC Curve</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2887fdaf",
   "metadata": {},
   "source": [
    "(Not applicable for Harmonized Sentiment dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0981f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the probabilities of the test data\n",
    "test_probabilities = logreg.predict_proba(test_features_vectorized)[:, 1]\n",
    "\n",
    "# Print the predicted labels\n",
    "print(test_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb1c847",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(test_labels, test_probabilities)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.plot(fpr, tpr, label='ROC curve (AUC = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae61a105",
   "metadata": {},
   "source": [
    "**HARMONIZED SENTIMENT TWEETS DATASET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47efb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Binarize the test labels\n",
    "binarized_labels = label_binarize(test_labels, classes=[0, 1, 2, 3])\n",
    "\n",
    "# Compute the probability predictions for each class\n",
    "test_probabilities = logreg.predict_proba(test_features)\n",
    "\n",
    "# Compute the ROC curve and ROC AUC score for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "n_classes = len(sentiment_labels)\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(binarized_labels[:, i], test_probabilities[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC AUC score\n",
    "fpr_micro, tpr_micro, _ = roc_curve(binarized_labels.ravel(), test_probabilities.ravel())\n",
    "roc_auc_micro = auc(fpr_micro, tpr_micro)\n",
    "\n",
    "# Plot ROC curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot micro-average ROC curve\n",
    "plt.plot(fpr_micro, tpr_micro, label='Micro-average ROC curve (area = {0:0.2f})'\n",
    "         ''.format(roc_auc_micro), linestyle=':', linewidth=4)\n",
    "\n",
    "# Plot ROC curve for each class\n",
    "for i in range(n_classes):\n",
    "    plt.plot(fpr[i], tpr[i], label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(sentiment_labels[i], roc_auc[i]), linewidth=2)\n",
    "\n",
    "# Add plot labels and legends\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be39ee0b",
   "metadata": {},
   "source": [
    "<h2> B. K-fold Cross Validation </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff99cd20",
   "metadata": {},
   "source": [
    "Use the cross_val_score() function from sklearn.model_selection to evaluate the performance of the classifier using 5-fold cross-validation. \n",
    "<br></br>\n",
    "The cross_val_score() function takes the classifier, the feature vectors, the labels, and the number of folds as input, and returns an array of scores for each fold\n",
    "\n",
    "**Output: Cross-validation scores for each fold + Average cross-validation score**\n",
    "\n",
    "Note: cv = k (k-fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ab30ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Perform k-fold cross-validation and obtain the scores for each fold\n",
    "scores = cross_val_score(logreg, train_features_vectorized, train_labels, cv=10)\n",
    "\n",
    "# Print the accuracy for each fold\n",
    "for fold, score in enumerate(scores):\n",
    "    print(f\"Fold {fold+1}: {score}\")\n",
    "\n",
    "# Calculate and print the mean accuracy and standard deviation\n",
    "mean_accuracy = scores.mean()\n",
    "std_deviation = scores.std()\n",
    "print(f\"Mean accuracy: {mean_accuracy}\")\n",
    "print(f\"Standard deviation: {std_deviation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04db2827",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Evaluate the performance of Logistic Regression classifier using cross-validation\n",
    "scores = cross_val_score(logreg, train_features_vectorized, train_labels, cv=10)\n",
    "\n",
    "# Print the cross-validation scores\n",
    "print(f\"Cross-validation scores: {scores}\")\n",
    "print(f\"Average cross-validation score: {scores.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fce9d21",
   "metadata": {},
   "source": [
    "<h2> C. Hyperparameter Tuning </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fe0100",
   "metadata": {},
   "source": [
    "**How to find the BEST hyperparameters for Logistic Regression classifier**\n",
    "\n",
    "The GridSearchCV() function takes the classifier, the hyperparameters, and the number of folds as input, and returns the best hyperparameters and the corresponding score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a59935",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create an instance of Multinomial Logistic Regression\n",
    "logreg = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "\n",
    "# Define the hyperparameters to search over\n",
    "hyperparameters = {'C': [0.1, 0.5, 1.0, 2.0, 5.0, 10.0]}\n",
    "\n",
    "# Use grid search to find the best hyperparameters for the classifier\n",
    "grid_search = GridSearchCV(logreg, hyperparameters, cv=10)\n",
    "grid_search.fit(train_features_vectorized, train_labels)\n",
    "\n",
    "# Print the best hyperparameters and the corresponding score\n",
    "print(f\"Best hyperparameters: {grid_search.best_params_}\")\n",
    "print(f\"Best score: {grid_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc55abe",
   "metadata": {},
   "source": [
    "We then print the best hyperparameters and the corresponding score using the print() function. The resulting output will show the best hyperparameters found by the grid search and the corresponding score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c28cbb",
   "metadata": {},
   "source": [
    "After finding the best hyperparameters, you can process to train and evaluate Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01976907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN values with an empty string\n",
    "train_features = np.where(pd.isnull(train_features), '', train_features)\n",
    "\n",
    "# Create an instance of CountVectorizer\n",
    "#vectorizer = TfidfVectorizer() # For TF-IDF\n",
    "vectorizer = CountVectorizer()  # For BoW\n",
    "\n",
    "# Fit the vectorizer on the training data and transform the training features\n",
    "train_features_vectorized = vectorizer.fit_transform(train_features)\n",
    "\n",
    "# Transform the testing features using the trained vectorizer\n",
    "test_features_vectorized = vectorizer.transform(test_features)\n",
    "\n",
    "train_features_vectorized.shape, test_features_vectorized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065a39a4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# Remember to modify test size each time you're trying to run a new model!!\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, encoded_labels, \n",
    "                                                                            test_size=0.2, random_state=42)\n",
    "\n",
    "# Replace NaN values with an empty string\n",
    "train_features = np.where(pd.isnull(train_features), '', train_features)\n",
    "\n",
    "# Create an instance of CountVectorizer\n",
    "#vectorizer = TfidfVectorizer() # For TF-IDF\n",
    "vectorizer = CountVectorizer()  # For BoW\n",
    "\n",
    "# Fit the vectorizer on the training data and transform the training features\n",
    "train_features_vectorized = vectorizer.fit_transform(train_features)\n",
    "\n",
    "# Transform the testing features using the trained vectorizer\n",
    "test_features_vectorized = vectorizer.transform(test_features)\n",
    "\n",
    "# Create an instance of Multinomial Logistic Regression\n",
    "logreg = LogisticRegression(multi_class='multinomial', solver='lbfgs', C=2.0)\n",
    "\n",
    "# Train a Multinomial Logistic Regression classifier on the training data\n",
    "logreg.fit(train_features_vectorized, train_labels)\n",
    "\n",
    "# Predict the labels of the test data\n",
    "test_predictions = logreg.predict(test_features_vectorized)\n",
    "\n",
    "# Evaluate the performance of the classifier on the test data\n",
    "confusion = confusion_matrix(test_labels, test_predictions)\n",
    "report = classification_report(test_labels, test_predictions)\n",
    "accuracy = accuracy_score(test_labels, test_predictions)\n",
    "\n",
    "# Print the confusion matrix, classification report, and accuracy score\n",
    "print(f\"Confusion matrix:\\n{confusion}\")\n",
    "print(f\"Classification report:\\n{report}\")\n",
    "print(f\"Accuracy score: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2922bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(test_labels, test_predictions)\n",
    "\n",
    "# Calculate the precision of the classifier\n",
    "precision = precision_score(test_labels, test_predictions, average='weighted')\n",
    "\n",
    "# Calculate the recall of the classifier\n",
    "recall = recall_score(test_labels, test_predictions, average='weighted')\n",
    "\n",
    "# Calculate the F1 score of the classifier\n",
    "f1 = f1_score(test_labels, test_predictions, average='weighted')\n",
    "\n",
    "# Calculate the confusion matrix of the classifier\n",
    "confusion_mat = confusion_matrix(test_labels, test_predictions)\n",
    "\n",
    "# Define the labels for the confusion matrix\n",
    "labels = ['True Negative (TN)', 'False Positive (FP)', 'False Negative (FN)', 'True Positive (TP)']\n",
    "\n",
    "# Create a new confusion matrix with the labels\n",
    "confusion_mat_labeled = np.empty((2,2), dtype=int)\n",
    "confusion_mat_labeled[0,0] = confusion_mat[0,0] # True Negative\n",
    "confusion_mat_labeled[0,1] = confusion_mat[0,1] # False Positive\n",
    "confusion_mat_labeled[1,0] = confusion_mat[1,0] # False Negative\n",
    "confusion_mat_labeled[1,1] = confusion_mat[1,1] # True Positive\n",
    "\n",
    "# Create a DataFrame with the confusion matrix and labels\n",
    "confusion_df = pd.DataFrame(confusion_mat_labeled, index=labels[:2], columns=labels[2:])\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Evaluation Metrics:\")\n",
    "print(\"Accuracy:\", accuracy * 100, \"%\")\n",
    "print(\"Precision:\", precision * 100, \"%\")\n",
    "print(\"Recall:\", recall * 100, \"%\")\n",
    "print(\"F1 Score:\", f1 * 100, \"%\")\n",
    "display(\"Confusion Matrix:\", confusion_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebc64bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store the evaluation metrics (After tuning)\n",
    "evaluation_results = {\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "    'Score': [accuracy, precision, recall, f1]\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the evaluation results\n",
    "df_evaluation = pd.DataFrame(evaluation_results)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix\n",
    "confusion_df = pd.DataFrame(confusion_mat, columns=['False Negative', 'False Positive'], index=['True Negative', 'True Positive'])\n",
    "\n",
    "# Concatenate the evaluation DataFrame and confusion DataFrame\n",
    "results_df = pd.concat([df_evaluation, confusion_df], axis=0)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "results_df.to_csv('[TextBlob] MLR BOW (70-30) Post Hypertuning Model_Evaluation.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c009730c",
   "metadata": {},
   "source": [
    "## 5. Predict Sentiment of New text Data<a name=\"Section5\"></a>\n",
    "Back to [Top Page](#TOC)\n",
    "\n",
    "Using the trained model classifier, we can predict the sentiment of new text data\n",
    "<br>\n",
    "\n",
    "Positive [1] - Food Secured\n",
    "\n",
    "Negative [0] - Food Insecure\n",
    "\n",
    "A) [VADER/TextBlob Dataset](#Section14)\n",
    "<br>\n",
    "B) [Harmonized Dataset](#Section15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f4ee62",
   "metadata": {},
   "source": [
    "### A) VADER/TextBlob Dataset<a name=\"Section14\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e051c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create a CountVectorizer object\n",
    "#vectorizer = TfidfVectorizer() # For TF-IDF\n",
    "vectorizer = CountVectorizer() # For BOW\n",
    "\n",
    "# Vectorize the training data\n",
    "features_vectorized = vectorizer.fit_transform(train_features)\n",
    "\n",
    "# Create an instance of Multinomial Logistic Regression\n",
    "logreg = LogisticRegression(multi_class='multinomial', solver='lbfgs', C=2.0)\n",
    "\n",
    "# Train a Multinomial Logistic Regression classifier on the training data\n",
    "logreg.fit(train_features_vectorized, train_labels)\n",
    "\n",
    "# Predict the sentiment of new text data\n",
    "new_data = [\"I'm so angry about the high food prices! It's making it so hard for me to feed my family.\",\n",
    "            \"I'm so grateful for the food banks and other organizations that are helping to feed people who are struggling. They're making a real difference.\",\n",
    "            \"I'm so worried about the future of food security. Climate change is making it harder to grow food, and more people are going hungry.\",\n",
    "            \"I'm so inspired by the work of food banks and other organizations that are fighting hunger. They're making a real difference in people's lives.\",\n",
    "            \"I'm hopeful that we can create a world where everyone has access to the food they need to live a healthy and productive life\"]\n",
    "\n",
    "new_data_vectorized = vectorizer.transform(new_data)\n",
    "new_data_predictions = logreg.predict(new_data_vectorized)\n",
    "new_data_sentiment_scores = logreg.predict_proba(new_data_vectorized)[:, 1]  # Positive sentiment score\n",
    "\n",
    "# Print the predicted sentiment + sentiment scoures for the new data\n",
    "for i in range(len(new_data)):\n",
    "    print(f\"Text: {new_data[i]}\")\n",
    "    sentiment_label = \"Food Secured\" if new_data_predictions[i] == 1 else \"Food Insecure\"\n",
    "    print(f\"Predicted sentiment: {sentiment_label}\")\n",
    "    print(f\"Sentiment score: {new_data_sentiment_scores[i]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5715af83",
   "metadata": {},
   "source": [
    "**Save the new data results into CSV file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f1c581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame to store the results\n",
    "results_df = pd.DataFrame({\n",
    "    'Text': new_data,\n",
    "    'Predicted Sentiment': new_data_predictions,\n",
    "    'Sentiment Score': new_data_sentiment_scores\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "results_df.to_csv('[SAMPLE] [MLR] BOW Harmonized (80-20) new_data_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1fd0db",
   "metadata": {},
   "source": [
    "### B) Harmonized Dataset<a name=\"Section15\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1306bc94",
   "metadata": {},
   "source": [
    "**Predict sentiment & FI Risk Category of New Text Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0dce7f",
   "metadata": {},
   "source": [
    "**For Harmonized Sentiment Tweets Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267d59cb",
   "metadata": {},
   "source": [
    "### Immediate Solution for Predicting FI Risk <a name=\"Section16\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5696851",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define the risk category mapping\n",
    "risk_category_mapping = {\n",
    "    0: \"\\033[1;32mLow Risk\\033[0m\",  # Green\n",
    "    1: \"\\033[1;33mMild Risk\\033[0m\", # Yellow\n",
    "    2: \"\\033[1;31mModerate Risk\\033[0m\", # Orange\n",
    "    3: \"\\033[1;31mSevere Risk\\033[0m\"  # Red\n",
    "}\n",
    "\n",
    "# Create a CountVectorizer object\n",
    "#vectorizer = TfidfVectorizer() # For TF-IDF\n",
    "vectorizer = CountVectorizer() # For BOW\n",
    "\n",
    "# Vectorize the training data\n",
    "features_vectorized = vectorizer.fit_transform(train_features)\n",
    "\n",
    "# Create an instance of Multinomial Logistic Regression\n",
    "logreg = LogisticRegression(multi_class='multinomial', solver='lbfgs', C=52.0)\n",
    "\n",
    "# Train a Multinomial Logistic Regression classifier on the training data\n",
    "logreg.fit(train_features_vectorized, train_labels)\n",
    "\n",
    "# Function to predict sentiment, sentiment score, and FI risk category of new text data\n",
    "def predict_sentiment_and_fi_risk(text):\n",
    "    # Vectorize the new text data\n",
    "    new_text_vectorized = vectorizer.transform([text])\n",
    "\n",
    "    # Predict the sentiment using the trained model\n",
    "    sentiment = logreg.predict(new_text_vectorized)[0]\n",
    "\n",
    "    # Predict the sentiment score using the trained model\n",
    "    sentiment_score = np.max(logreg.predict_proba(new_text_vectorized))\n",
    "\n",
    "    # Assign the FI risk category based on sentiment and sentiment score\n",
    "    if sentiment == 1:  # Positive sentiment (Food Secured)\n",
    "        fi_sentiment = \"Positive\"\n",
    "        fi_risk = risk_category_mapping[0]  # Low Risk\n",
    "    else:  # Negative sentiment\n",
    "        sentiment_score *= -1  # Multiply the sentiment score by -1 for Negative sentiment (Food Insecure)\n",
    "        \n",
    "        if (sentiment_score > -1.0) and (sentiment_score <= -0.6):\n",
    "            fi_sentiment = \"Negative (Strongly Negative)\"\n",
    "            fi_risk = risk_category_mapping[3]  # Severe Risk\n",
    "        elif (sentiment_score > -0.6) and (sentiment_score <= -0.3):\n",
    "            fi_sentiment = \"Negative (Mild Negative)\"\n",
    "            fi_risk = risk_category_mapping[2]  # Moderate Risk\n",
    "        else:\n",
    "            fi_sentiment = \"Negative (Weakly Negative)\"\n",
    "            fi_risk = risk_category_mapping[1]  # Mild Risk\n",
    "\n",
    "    return fi_sentiment, sentiment_score, fi_risk\n",
    "\n",
    "\n",
    "# Predict the sentiment, sentiment score, and FI risk for the new text data\n",
    "new_data = [\n",
    "    \"I'm so angry about the high food prices! It's making it so hard for me to feed my family.\",\n",
    "    \"I'm so grateful for the food banks and other organizations that are helping to feed people who are struggling. They're making a real difference.\",\n",
    "    \"I'm so worried about the future of food security. Climate change is making it harder to grow food, and more people are going hungry.\",\n",
    "    \"I'm so inspired by the work of food banks and other organizations that are fighting hunger. They're making a real difference in people's lives.\",\n",
    "    \"I'm hopeful that we can create a world where everyone has access to the food they need to live a healthy and productive life\",\n",
    "    \"I'm working part-time and I'm not sure if I'll be able to keep my job.\",\n",
    "    \"I'm not sure if I'll be able to afford to pay my rent this month.\"\n",
    "]\n",
    "\n",
    "final_results = []\n",
    "for text in new_data:\n",
    "    fi_sentiment, sentiment_score, fi_risk = predict_sentiment_and_fi_risk(text)\n",
    "    print(\"Text:\", text)\n",
    "    print(\"Predicted sentiment:\", fi_sentiment)\n",
    "    print(\"Sentiment score:\", sentiment_score)\n",
    "    print(\"FI Risk:\", fi_risk)\n",
    "    print()\n",
    "    \n",
    "    # Store the results in a dictionary\n",
    "    final_result = {\n",
    "        \"Text\": text,\n",
    "        \"Predicted Sentiment\": fi_sentiment,\n",
    "        \"Sentiment Score\": sentiment_score,\n",
    "        \"FI Risk\": fi_risk\n",
    "    }\n",
    "    final_results.append(final_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031ee55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for the results\n",
    "final_results_df = pd.DataFrame(final_results)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(final_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa135a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "final_results_df.to_csv('[SAMPLE] [MLR] BOW Harmonized (80-20) final new_data_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2499db",
   "metadata": {},
   "source": [
    "## 5. Visualization<a name=\"Section5\"></a>\n",
    "<br></br>\n",
    "**Type of Visualizations:**\n",
    "1. Heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6181db3",
   "metadata": {},
   "source": [
    "**Heatmap**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7131c1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Plotting the heatmap of confusion matrix\n",
    "cm = confusion_matrix(test_labels, test_predictions)\n",
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b7d97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Define the labels for the confusion matrix\n",
    "labels = ['True Negative', 'False Positive', 'False Negative', 'True Positive']\n",
    "\n",
    "# Create a new confusion matrix with the labels\n",
    "confusion_mat_labeled = np.empty((2,2), dtype=int)\n",
    "confusion_mat_labeled[0,0] = confusion_mat[0,0] # True Negative\n",
    "confusion_mat_labeled[0,1] = confusion_mat[0,1] # False Positive\n",
    "confusion_mat_labeled[1,0] = confusion_mat[1,0] # False Negative\n",
    "confusion_mat_labeled[1,1] = confusion_mat[1,1] # True Positive\n",
    "\n",
    "# Create a DataFrame with the confusion matrix and labels\n",
    "confusion_df = pd.DataFrame(confusion_mat_labeled, index=labels[:2], columns=labels[2:])\n",
    "\n",
    "# Create a heatmap of the confusion matrix\n",
    "sns.heatmap(confusion_df, annot=True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2698326",
   "metadata": {},
   "source": [
    "**For Harmonized Sentiment Tweets Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8779db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Perform predictions on the test data\n",
    "test_predictions = logreg.predict(test_features_vectorized)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "confusion_mat = confusion_matrix(test_labels, test_predictions)\n",
    "\n",
    "# Create a list of sentiment labels\n",
    "sentiment_labels = [\"0\", \"1\", \"2\", \"3\"]\n",
    "\n",
    "# Create a heatmap of the confusion matrix\n",
    "sns.heatmap(confusion_mat, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=sentiment_labels, yticklabels=sentiment_labels)\n",
    "\n",
    "# Set the axis labels and title\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
