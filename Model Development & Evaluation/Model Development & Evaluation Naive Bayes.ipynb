{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "354ebecb",
   "metadata": {},
   "source": [
    "<h1>Model Development: Naive Bayes</h1>\n",
    "\n",
    "Source: https://gist.github.com/xiaofan-lei/397724d9f997dd9e68963f99dd2025ae#file-3-naivebayes-sentimentanalysis-py\n",
    "\n",
    "## Table of Contents<a name=\"TOC\"></a>\n",
    "\n",
    "1. [Splitting the Dataset Into Training and Testing Sets](#Section1)\n",
    "<br>First, separate the columns into dependent and independent variables (or features and labels). Then you split those variables into train and test sets.</br>\n",
    "\n",
    "2. [Feature Extraction](#Section2)\n",
    "<br>Includes document-term matirx (TF-IDF & BOW)</br>\n",
    "\n",
    "3. [Model Generation](#Section3)\n",
    "<br>Building SA Modelling using **Naive Bayes**</br>\n",
    "\n",
    "4. [Model Evaluation](#Section4)\n",
    "<br>Evaluate the Naive Bayes modelling based on performance metrics</br>\n",
    "\n",
    "5. [Visualization](#Section5)\n",
    "<br>Heatmpas and Stacked Bar Charts</br>\n",
    "\n",
    "To save the model, click [here](#Section15)\n",
    "\n",
    "Approach:\n",
    "1. Sentiment Analysis Modelling using Naive Bayes\n",
    "\n",
    "2. Predicting Sentiment using Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab4b282",
   "metadata": {},
   "source": [
    "**Importing libraries & dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cd2066",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import nltk\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94270d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Username</th>\n",
       "      <th>Cleaned_Tweets</th>\n",
       "      <th>Location</th>\n",
       "      <th>VADER_score</th>\n",
       "      <th>TextBlob_score</th>\n",
       "      <th>Harmonized_Score</th>\n",
       "      <th>Harmonized_Label</th>\n",
       "      <th>Risk_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27/1/2023 14:32</td>\n",
       "      <td>Don Dale</td>\n",
       "      <td>buying forget review first guy feel want comme...</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>0.6703</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>0.210150</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Low Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27/1/2023 19:04</td>\n",
       "      <td>Iliani</td>\n",
       "      <td>food security research going explode issue end...</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>0.5859</td>\n",
       "      <td>-0.181818</td>\n",
       "      <td>0.202041</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Low Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29/1/2023 8:28</td>\n",
       "      <td>Naim Zaini</td>\n",
       "      <td>context slaughtered food muslim consideration ...</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>0.8658</td>\n",
       "      <td>0.034722</td>\n",
       "      <td>0.450261</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Low Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29/1/2023 13:29</td>\n",
       "      <td>??</td>\n",
       "      <td>raise food price wet good expensive sorry guy</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>0.3818</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.140900</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Low Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30/1/2023 21:52</td>\n",
       "      <td>Alinosourawr</td>\n",
       "      <td>che restaurant sek send food x order food drin...</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>-0.8934</td>\n",
       "      <td>-0.433333</td>\n",
       "      <td>-0.663367</td>\n",
       "      <td>Strongly Negative</td>\n",
       "      <td>Severe Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21832</th>\n",
       "      <td>2023-03-30 23:45:13+00:00</td>\n",
       "      <td>Charrlygirl</td>\n",
       "      <td>worried prosecution team family also worried f...</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>-0.8360</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.418000</td>\n",
       "      <td>Mild Negative</td>\n",
       "      <td>Moderate Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21833</th>\n",
       "      <td>2023-03-30 23:49:23+00:00</td>\n",
       "      <td>angel19971102</td>\n",
       "      <td>love much clark must always worried bruce drea...</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>0.6939</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.546950</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Low Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21834</th>\n",
       "      <td>2023-03-30 23:55:01+00:00</td>\n",
       "      <td>firdyfire</td>\n",
       "      <td>industry player worried energy commission chie...</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>-0.0258</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.012900</td>\n",
       "      <td>Weakly Negative</td>\n",
       "      <td>Mild Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21835</th>\n",
       "      <td>2023-03-30 23:55:16+00:00</td>\n",
       "      <td>AhmadMuhyie</td>\n",
       "      <td>ah really weak faith fasting without real exam...</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>0.6222</td>\n",
       "      <td>0.239583</td>\n",
       "      <td>0.430892</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Low Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21836</th>\n",
       "      <td>2023-03-30 23:57:11+00:00</td>\n",
       "      <td>farhinsyirh</td>\n",
       "      <td>hate sin man know recorded video amazes contin...</td>\n",
       "      <td>Johore, Malaysia</td>\n",
       "      <td>-0.2167</td>\n",
       "      <td>-0.288889</td>\n",
       "      <td>-0.252794</td>\n",
       "      <td>Weakly Negative</td>\n",
       "      <td>Mild Risk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21837 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Datetime       Username   \n",
       "0                27/1/2023 14:32       Don Dale  \\\n",
       "1                27/1/2023 19:04         Iliani   \n",
       "2                 29/1/2023 8:28     Naim Zaini   \n",
       "3                29/1/2023 13:29             ??   \n",
       "4                30/1/2023 21:52   Alinosourawr   \n",
       "...                          ...            ...   \n",
       "21832  2023-03-30 23:45:13+00:00    Charrlygirl   \n",
       "21833  2023-03-30 23:49:23+00:00  angel19971102   \n",
       "21834  2023-03-30 23:55:01+00:00      firdyfire   \n",
       "21835  2023-03-30 23:55:16+00:00    AhmadMuhyie   \n",
       "21836  2023-03-30 23:57:11+00:00    farhinsyirh   \n",
       "\n",
       "                                          Cleaned_Tweets          Location   \n",
       "0      buying forget review first guy feel want comme...          Malaysia  \\\n",
       "1      food security research going explode issue end...          Malaysia   \n",
       "2      context slaughtered food muslim consideration ...          Malaysia   \n",
       "3          raise food price wet good expensive sorry guy          Malaysia   \n",
       "4      che restaurant sek send food x order food drin...          Malaysia   \n",
       "...                                                  ...               ...   \n",
       "21832  worried prosecution team family also worried f...          Malaysia   \n",
       "21833  love much clark must always worried bruce drea...          Malaysia   \n",
       "21834  industry player worried energy commission chie...          Malaysia   \n",
       "21835  ah really weak faith fasting without real exam...          Malaysia   \n",
       "21836  hate sin man know recorded video amazes contin...  Johore, Malaysia   \n",
       "\n",
       "       VADER_score  TextBlob_score  Harmonized_Score   Harmonized_Label   \n",
       "0           0.6703       -0.250000          0.210150           Positive  \\\n",
       "1           0.5859       -0.181818          0.202041           Positive   \n",
       "2           0.8658        0.034722          0.450261           Positive   \n",
       "3           0.3818       -0.100000          0.140900           Positive   \n",
       "4          -0.8934       -0.433333         -0.663367  Strongly Negative   \n",
       "...            ...             ...               ...                ...   \n",
       "21832      -0.8360        0.000000         -0.418000      Mild Negative   \n",
       "21833       0.6939        0.400000          0.546950           Positive   \n",
       "21834      -0.0258        0.000000         -0.012900    Weakly Negative   \n",
       "21835       0.6222        0.239583          0.430892           Positive   \n",
       "21836      -0.2167       -0.288889         -0.252794    Weakly Negative   \n",
       "\n",
       "          Risk_Label  \n",
       "0           Low Risk  \n",
       "1           Low Risk  \n",
       "2           Low Risk  \n",
       "3           Low Risk  \n",
       "4        Severe Risk  \n",
       "...              ...  \n",
       "21832  Moderate Risk  \n",
       "21833       Low Risk  \n",
       "21834      Mild Risk  \n",
       "21835       Low Risk  \n",
       "21836      Mild Risk  \n",
       "\n",
       "[21837 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load csv file containing tweets dataset (w/ sentiments)\n",
    "\n",
    "tweets_df = pd.read_csv(r\"C:\\Users\\LENOVO\\Documents\\Degree Life\\FYP Journey\\Dataset\\Sentiment Analysis\\V3 Harmonized [VADER & TextBlob]_All Keywords (Whole Malaysia).csv\")\n",
    "display(tweets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ed8c127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cleaned_Tweets</th>\n",
       "      <th>Harmonized_Score</th>\n",
       "      <th>Harmonized_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>buying forget review first guy feel want comme...</td>\n",
       "      <td>0.210150</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>food security research going explode issue end...</td>\n",
       "      <td>0.202041</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>context slaughtered food muslim consideration ...</td>\n",
       "      <td>0.450261</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>raise food price wet good expensive sorry guy</td>\n",
       "      <td>0.140900</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>che restaurant sek send food x order food drin...</td>\n",
       "      <td>-0.663367</td>\n",
       "      <td>Strongly Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21832</th>\n",
       "      <td>worried prosecution team family also worried f...</td>\n",
       "      <td>-0.418000</td>\n",
       "      <td>Mild Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21833</th>\n",
       "      <td>love much clark must always worried bruce drea...</td>\n",
       "      <td>0.546950</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21834</th>\n",
       "      <td>industry player worried energy commission chie...</td>\n",
       "      <td>-0.012900</td>\n",
       "      <td>Weakly Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21835</th>\n",
       "      <td>ah really weak faith fasting without real exam...</td>\n",
       "      <td>0.430892</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21836</th>\n",
       "      <td>hate sin man know recorded video amazes contin...</td>\n",
       "      <td>-0.252794</td>\n",
       "      <td>Weakly Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21837 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Cleaned_Tweets  Harmonized_Score   \n",
       "0      buying forget review first guy feel want comme...          0.210150  \\\n",
       "1      food security research going explode issue end...          0.202041   \n",
       "2      context slaughtered food muslim consideration ...          0.450261   \n",
       "3          raise food price wet good expensive sorry guy          0.140900   \n",
       "4      che restaurant sek send food x order food drin...         -0.663367   \n",
       "...                                                  ...               ...   \n",
       "21832  worried prosecution team family also worried f...         -0.418000   \n",
       "21833  love much clark must always worried bruce drea...          0.546950   \n",
       "21834  industry player worried energy commission chie...         -0.012900   \n",
       "21835  ah really weak faith fasting without real exam...          0.430892   \n",
       "21836  hate sin man know recorded video amazes contin...         -0.252794   \n",
       "\n",
       "        Harmonized_Label  \n",
       "0               Positive  \n",
       "1               Positive  \n",
       "2               Positive  \n",
       "3               Positive  \n",
       "4      Strongly Negative  \n",
       "...                  ...  \n",
       "21832      Mild Negative  \n",
       "21833           Positive  \n",
       "21834    Weakly Negative  \n",
       "21835           Positive  \n",
       "21836    Weakly Negative  \n",
       "\n",
       "[21837 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#drop irrelvant columns for modelling purposes\n",
    "#Irrelevant columns = \"Datetime\", \"Username\", \"Location\"\n",
    "new_df = tweets_df.drop(['Datetime', 'Username','Location'], axis=1)\n",
    "\n",
    "# Create a list of the column names in the desired order\n",
    "cols = ['Cleaned_Tweets', 'Harmonized_Score','Harmonized_Label']\n",
    "\n",
    "# Rearrange the columns in the dataset\n",
    "new_df = new_df[cols]\n",
    "\n",
    "display(new_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c68f20",
   "metadata": {},
   "source": [
    "## 1. Splitting the Dataset Into Training and Testing Sets<a name=\"Section1\"></a>\n",
    "\n",
    "<img src=\"https://editor.analyticsvidhya.com/uploads/63129111111.png\">\n",
    "\n",
    "<br>\n",
    "LabelEncoder() from sklearn.preprocessing is used to convert the labels (‘positive’, ‘negative’) into 1’s and 0’s respectively\n",
    "</br>\n",
    "\n",
    "The dataset is then split into 2 different train-test splits using train_test_split from sklearn.model_selection.\n",
    "\n",
    "1. 70:30\n",
    "2. 80:20\n",
    "\n",
    "Modified source code found from this website: https://www.analyticsvidhya.com/blog/2022/03/building-naive-bayes-classifier-from-scratch-to-perform-sentiment-analysis/\n",
    "\n",
    "**For Harmonized Sentiment Dataset**\n",
    "<br>\n",
    "Sentiment Label 0: \"Positive - Food Secured\"\n",
    "<br>\n",
    "Sentiment Label 1: \"Low FI Risk\" (Positive Sentiment)\n",
    "<br>\n",
    "Sentiment Label 2: \"Mild FI Risk\" (Weakly Negative)\n",
    "<br>\n",
    "Sentiment Label 3: \"Moderate FI Risk\" (Mild Negative)\n",
    "<br>\n",
    "Sentiment Label 4: \"Severe FI Risk\" (Strongly Negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "434dacde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the features and labels\n",
    "features = new_df['Cleaned_Tweets'].values\n",
    "labels = new_df['Harmonized_Label'].values\n",
    "\n",
    "# Use LabelEncoder to convert labels to numerical values\n",
    "# Positive [1] OR Negative [0]\n",
    "encoder = LabelEncoder()\n",
    "encoded_labels = encoder.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31b273c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15285,), (6552,), (15285,), (6552,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "# Remember to modify test size each time you're trying to run a new model!!\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, encoded_labels, \n",
    "                                                                            test_size=0.3, random_state=42)\n",
    "train_features.shape, test_features.shape, train_labels.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41ec95bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cleaned_Tweets</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eat buffet le bt ctw lawn offered top supermar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hungry time</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>good learn psychology eg think someone really ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jokowi volunteer gather gbk alhamdulillah gath...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>addition holding back hunger thirst also hold ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15280</th>\n",
       "      <td>power hungry selfish narcissistic unpatriotic ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15281</th>\n",
       "      <td>depending deed think read quran ramadan cake b...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15282</th>\n",
       "      <td>yummy feeling hungry back</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15283</th>\n",
       "      <td>weight worried pr</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15284</th>\n",
       "      <td>keeping hunger drive inside clip podcast tm cy...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15285 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Cleaned_Tweets  Sentiment\n",
       "0      eat buffet le bt ctw lawn offered top supermar...          1\n",
       "1                                            hungry time          1\n",
       "2      good learn psychology eg think someone really ...          1\n",
       "3      jokowi volunteer gather gbk alhamdulillah gath...          1\n",
       "4      addition holding back hunger thirst also hold ...          3\n",
       "...                                                  ...        ...\n",
       "15280  power hungry selfish narcissistic unpatriotic ...          1\n",
       "15281  depending deed think read quran ramadan cake b...          3\n",
       "15282                          yummy feeling hungry back          1\n",
       "15283                                  weight worried pr          3\n",
       "15284  keeping hunger drive inside clip podcast tm cy...          3\n",
       "\n",
       "[15285 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert train_features and train_labels back to Pandas DataFrames\n",
    "train_data = pd.DataFrame({'Cleaned_Tweets': train_features, 'Sentiment': train_labels})\n",
    "#train_data = pd.concat([train_features.reset_index(drop=True), train_labels.reset_index(drop=True)], axis=1)\n",
    "display(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d924568c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cleaned_Tweets</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hungry cook</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>want take responsibility accnt endo getting ne...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>please relax worried know love work please lov...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>annual agenda pansos hurry came path individua...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>okay csb worried growing old ouch inner tita g...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6547</th>\n",
       "      <td>according estimate lost wasted could feed bill...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6548</th>\n",
       "      <td>worried thai aluminum work leave building resp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6549</th>\n",
       "      <td>cheap sunny good food gave creature comfort ci...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6550</th>\n",
       "      <td>sodiq rishema hour stomach hungry</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6551</th>\n",
       "      <td>close minute waiting rice wedding rice gone mc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6552 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Cleaned_Tweets  Sentiment\n",
       "0                                           hungry cook          1\n",
       "1     want take responsibility accnt endo getting ne...          1\n",
       "2     please relax worried know love work please lov...          1\n",
       "3     annual agenda pansos hurry came path individua...          0\n",
       "4     okay csb worried growing old ouch inner tita g...          3\n",
       "...                                                 ...        ...\n",
       "6547  according estimate lost wasted could feed bill...          0\n",
       "6548  worried thai aluminum work leave building resp...          1\n",
       "6549  cheap sunny good food gave creature comfort ci...          1\n",
       "6550                  sodiq rishema hour stomach hungry          1\n",
       "6551  close minute waiting rice wedding rice gone mc...          1\n",
       "\n",
       "[6552 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert test_features and test_labels back to Pandas DataFrames\n",
    "test_data = pd.DataFrame({'Cleaned_Tweets': test_features, 'Sentiment': test_labels})\n",
    "display(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833c2333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the training set to a CSV file\n",
    "train_data.to_csv('(80-20) Harmonized train_data [Random State = 0].csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe1c5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the training set to a CSV file\n",
    "test_data.to_csv('(80-20) Harmonized test_data [Random State = 0].csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa9bceb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#view tweet length in train data and test data\n",
    "\n",
    "length_train = train_data['Cleaned_Tweets'].str.len()\n",
    "length_test = test_data['Cleaned_Tweets'].str.len()\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(length_train, bins=50, label=\"Train_tweets\", color = \"darkblue\")\n",
    "plt.hist(length_test, bins=50, label='Test_tweets', color = \"skyblue\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83415783",
   "metadata": {},
   "source": [
    "**To check if the dataset is balanced**\n",
    "\n",
    "Source: https://towardsdatascience.com/fine-grained-sentiment-analysis-in-python-part-1-2697bb111ed4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bd0add",
   "metadata": {},
   "source": [
    "For Harmonized Sentiments dataset, the following sentiment labels represented as follows:\n",
    "\n",
    "0 - Positive\n",
    "\n",
    "1 - Weakly Negative\n",
    "\n",
    "2 - Mild Negative\n",
    "\n",
    "3 - Strongly Negative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c3a8c8",
   "metadata": {},
   "source": [
    "**Train data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "893c5e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Label')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "ax = train_data['Sentiment'].value_counts(sort=False).plot(kind='barh')\n",
    "ax.set_xlabel(\"Number of Samples in Training Set\")\n",
    "ax.set_ylabel(\"Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "556a580c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For HARMONIZED dataset ONLY!\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the colors for each sentiment label\n",
    "colors = ['green', 'yellow', 'orange', 'red']\n",
    "\n",
    "# Plot the sentiment label counts with corresponding colors\n",
    "ax = train_data['Sentiment'].value_counts(sort=False).plot(kind='barh', color=colors)\n",
    "\n",
    "ax.set_xlabel(\"Number of Samples in Training Set\")\n",
    "ax.set_ylabel(\"Label\")\n",
    "\n",
    "# Add a legend for the colors\n",
    "legend_labels = ['Low FI Risk', 'Mild FI Risk', 'Moderate FI Risk', 'Severe FI Risk']\n",
    "legend_handles = [plt.Rectangle((0, 0), 1, 1, color=color) for color in colors]\n",
    "ax.legend(legend_handles, legend_labels)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a94aa3",
   "metadata": {},
   "source": [
    "**Test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed84867a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "ax = test_data['Sentiment'].value_counts(sort=False).plot(kind='barh')\n",
    "ax.set_xlabel(\"Number of Samples in Testing Set\")\n",
    "ax.set_ylabel(\"Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f13c978",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the colors for each sentiment label\n",
    "colors = ['green', 'yellow', 'orange', 'red']\n",
    "\n",
    "# Plot the sentiment label counts with corresponding colors\n",
    "ax = train_data['Sentiment'].value_counts(sort=False).plot(kind='barh', color=colors)\n",
    "\n",
    "ax.set_xlabel(\"Number of Samples in Training Set\")\n",
    "ax.set_ylabel(\"Label\")\n",
    "\n",
    "# Add a legend for the colors\n",
    "legend_labels = ['Low FI Risk', 'Mild FI Risk', 'Moderate FI Risk', 'Severe FI Risk']\n",
    "legend_handles = [plt.Rectangle((0, 0), 1, 1, color=color) for color in colors]\n",
    "ax.legend(legend_handles, legend_labels)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef060a51",
   "metadata": {},
   "source": [
    "## 2. Feature Extraction<a name=\"Section2\"></a>\n",
    "Using both TF-IDF and BOW for feature extraction\n",
    "\n",
    "Try to do it seperately for each modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543e7291",
   "metadata": {},
   "source": [
    "**A. TF-IDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0e2364f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15285, 21740), (6552, 21740))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace NaN values with an empty string\n",
    "train_features = np.where(pd.isnull(train_features), '', train_features)\n",
    "\n",
    "# Create an instance of CountVectorizer\n",
    "vectorizer = TfidfVectorizer()  # For TF-IDF\n",
    "\n",
    "# Fit the vectorizer on the training data and transform the training features\n",
    "train_features_vectorized = vectorizer.fit_transform(train_features)\n",
    "\n",
    "# Transform the testing features using the trained vectorizer\n",
    "test_features_vectorized = vectorizer.transform(test_features)\n",
    "\n",
    "train_features_vectorized.shape, test_features_vectorized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05614617",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features:\n",
      "         aa  aaa  aaaa  aaaaa  aaaaaaa  aaaaaaaaaaaaa  aaaaaaaaaaaaaahhhhh   \n",
      "0      0.0  0.0   0.0    0.0      0.0            0.0                  0.0  \\\n",
      "1      0.0  0.0   0.0    0.0      0.0            0.0                  0.0   \n",
      "2      0.0  0.0   0.0    0.0      0.0            0.0                  0.0   \n",
      "3      0.0  0.0   0.0    0.0      0.0            0.0                  0.0   \n",
      "4      0.0  0.0   0.0    0.0      0.0            0.0                  0.0   \n",
      "...    ...  ...   ...    ...      ...            ...                  ...   \n",
      "15280  0.0  0.0   0.0    0.0      0.0            0.0                  0.0   \n",
      "15281  0.0  0.0   0.0    0.0      0.0            0.0                  0.0   \n",
      "15282  0.0  0.0   0.0    0.0      0.0            0.0                  0.0   \n",
      "15283  0.0  0.0   0.0    0.0      0.0            0.0                  0.0   \n",
      "15284  0.0  0.0   0.0    0.0      0.0            0.0                  0.0   \n",
      "\n",
      "       aaaaaaaaaaarrrrrrrrr  aaarghhh  aaengai  ...  zuhur  zuiko  zul   \n",
      "0                       0.0       0.0      0.0  ...    0.0    0.0  0.0  \\\n",
      "1                       0.0       0.0      0.0  ...    0.0    0.0  0.0   \n",
      "2                       0.0       0.0      0.0  ...    0.0    0.0  0.0   \n",
      "3                       0.0       0.0      0.0  ...    0.0    0.0  0.0   \n",
      "4                       0.0       0.0      0.0  ...    0.0    0.0  0.0   \n",
      "...                     ...       ...      ...  ...    ...    ...  ...   \n",
      "15280                   0.0       0.0      0.0  ...    0.0    0.0  0.0   \n",
      "15281                   0.0       0.0      0.0  ...    0.0    0.0  0.0   \n",
      "15282                   0.0       0.0      0.0  ...    0.0    0.0  0.0   \n",
      "15283                   0.0       0.0      0.0  ...    0.0    0.0  0.0   \n",
      "15284                   0.0       0.0      0.0  ...    0.0    0.0  0.0   \n",
      "\n",
      "       zulkifli  zumba  zuzu   zz  zzzz  zzzzs  zzzzz  \n",
      "0           0.0    0.0   0.0  0.0   0.0    0.0    0.0  \n",
      "1           0.0    0.0   0.0  0.0   0.0    0.0    0.0  \n",
      "2           0.0    0.0   0.0  0.0   0.0    0.0    0.0  \n",
      "3           0.0    0.0   0.0  0.0   0.0    0.0    0.0  \n",
      "4           0.0    0.0   0.0  0.0   0.0    0.0    0.0  \n",
      "...         ...    ...   ...  ...   ...    ...    ...  \n",
      "15280       0.0    0.0   0.0  0.0   0.0    0.0    0.0  \n",
      "15281       0.0    0.0   0.0  0.0   0.0    0.0    0.0  \n",
      "15282       0.0    0.0   0.0  0.0   0.0    0.0    0.0  \n",
      "15283       0.0    0.0   0.0  0.0   0.0    0.0    0.0  \n",
      "15284       0.0    0.0   0.0  0.0   0.0    0.0    0.0  \n",
      "\n",
      "[15285 rows x 21740 columns]\n",
      "Testing Features:\n",
      "        aa  aaa  aaaa  aaaaa  aaaaaaa  aaaaaaaaaaaaa  aaaaaaaaaaaaaahhhhh   \n",
      "0     0.0  0.0   0.0    0.0      0.0            0.0                  0.0  \\\n",
      "1     0.0  0.0   0.0    0.0      0.0            0.0                  0.0   \n",
      "2     0.0  0.0   0.0    0.0      0.0            0.0                  0.0   \n",
      "3     0.0  0.0   0.0    0.0      0.0            0.0                  0.0   \n",
      "4     0.0  0.0   0.0    0.0      0.0            0.0                  0.0   \n",
      "...   ...  ...   ...    ...      ...            ...                  ...   \n",
      "6547  0.0  0.0   0.0    0.0      0.0            0.0                  0.0   \n",
      "6548  0.0  0.0   0.0    0.0      0.0            0.0                  0.0   \n",
      "6549  0.0  0.0   0.0    0.0      0.0            0.0                  0.0   \n",
      "6550  0.0  0.0   0.0    0.0      0.0            0.0                  0.0   \n",
      "6551  0.0  0.0   0.0    0.0      0.0            0.0                  0.0   \n",
      "\n",
      "      aaaaaaaaaaarrrrrrrrr  aaarghhh  aaengai  ...  zuhur  zuiko  zul   \n",
      "0                      0.0       0.0      0.0  ...    0.0    0.0  0.0  \\\n",
      "1                      0.0       0.0      0.0  ...    0.0    0.0  0.0   \n",
      "2                      0.0       0.0      0.0  ...    0.0    0.0  0.0   \n",
      "3                      0.0       0.0      0.0  ...    0.0    0.0  0.0   \n",
      "4                      0.0       0.0      0.0  ...    0.0    0.0  0.0   \n",
      "...                    ...       ...      ...  ...    ...    ...  ...   \n",
      "6547                   0.0       0.0      0.0  ...    0.0    0.0  0.0   \n",
      "6548                   0.0       0.0      0.0  ...    0.0    0.0  0.0   \n",
      "6549                   0.0       0.0      0.0  ...    0.0    0.0  0.0   \n",
      "6550                   0.0       0.0      0.0  ...    0.0    0.0  0.0   \n",
      "6551                   0.0       0.0      0.0  ...    0.0    0.0  0.0   \n",
      "\n",
      "      zulkifli  zumba  zuzu   zz  zzzz  zzzzs  zzzzz  \n",
      "0          0.0    0.0   0.0  0.0   0.0    0.0    0.0  \n",
      "1          0.0    0.0   0.0  0.0   0.0    0.0    0.0  \n",
      "2          0.0    0.0   0.0  0.0   0.0    0.0    0.0  \n",
      "3          0.0    0.0   0.0  0.0   0.0    0.0    0.0  \n",
      "4          0.0    0.0   0.0  0.0   0.0    0.0    0.0  \n",
      "...        ...    ...   ...  ...   ...    ...    ...  \n",
      "6547       0.0    0.0   0.0  0.0   0.0    0.0    0.0  \n",
      "6548       0.0    0.0   0.0  0.0   0.0    0.0    0.0  \n",
      "6549       0.0    0.0   0.0  0.0   0.0    0.0    0.0  \n",
      "6550       0.0    0.0   0.0  0.0   0.0    0.0    0.0  \n",
      "6551       0.0    0.0   0.0  0.0   0.0    0.0    0.0  \n",
      "\n",
      "[6552 rows x 21740 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert the sparse matrix to a dense matrix and create a DataFrame\n",
    "train_features_df = pd.DataFrame(train_features_vectorized.toarray(), columns=vectorizer.get_feature_names())\n",
    "test_features_df = pd.DataFrame(test_features_vectorized.toarray(), columns=vectorizer.get_feature_names())\n",
    "\n",
    "# Display the feature vectors\n",
    "print(\"Training Features:\\n\", train_features_df)\n",
    "print(\"Testing Features:\\n\", test_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1da07b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the train_features vectors to CSV files\n",
    "train_features_df.to_csv('TF-IDF (80-20)- Harmonized train_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48d766e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the test_features vectors to CSV files\n",
    "test_features_df.to_csv('TF-IDF (80-20)- Harmonized test_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8427f730",
   "metadata": {},
   "source": [
    "**B. BOW**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182d92c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN values with an empty string\n",
    "train_features = np.where(pd.isnull(train_features), '', train_features)\n",
    "\n",
    "# Create an instance of CountVectorizer\n",
    "vectorizer = CountVectorizer()  # For BoW\n",
    "\n",
    "# Fit the vectorizer on the training data and transform the training features\n",
    "train_features_vectorized = vectorizer.fit_transform(train_features)\n",
    "\n",
    "# Transform the testing features using the trained vectorizer\n",
    "test_features_vectorized = vectorizer.transform(test_features)\n",
    "\n",
    "train_features_vectorized.shape, test_features_vectorized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41acbb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the sparse matrix to a dense matrix and create a DataFrame\n",
    "train_features_df = pd.DataFrame(train_features_vectorized.toarray(), columns=vectorizer.get_feature_names())\n",
    "test_features_df = pd.DataFrame(test_features_vectorized.toarray(), columns=vectorizer.get_feature_names())\n",
    "\n",
    "# Display the feature vectors\n",
    "print(\"Training Features:\\n\", train_features_df)\n",
    "print(\"Testing Features:\\n\", test_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea425d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the train_features vectors to CSV files\n",
    "train_features_df.to_csv('BOW (70-30)- VADER train_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de514322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the test_features vectors to CSV files\n",
    "test_features_df.to_csv('BOW (70-30)- VADER test_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d582638a",
   "metadata": {},
   "source": [
    "## 3. Model Generation<a name=\"Section3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5005fac",
   "metadata": {},
   "source": [
    "## 3.1 Train model using Naive Bayes<a name=\"Section6\"></a>\n",
    "Naive bayes is an algorithm that could be used for sentiment analysis. It takes a short time to train and also has a short prediction time.\n",
    "\n",
    "\n",
    "How to train a Naive Bayes classifier?\n",
    "- The first part of training a naive bayes classifier is to identify the number of classes that you have.\n",
    "- We will create a probability for each class.\n",
    "\n",
    "**Approach**\n",
    "\n",
    "1. [Multinomial Naive Bayes (MNB)](#Section13)\n",
    "<br></br>\n",
    "2. [Bernoulli Naive Bayes (BNB)](#Section14)\n",
    "\n",
    "Tip:\n",
    "- If the words can be represented in terms of their occurrences (frequency count) = Use **Multinomial** \n",
    "- If we just care about the presence or absence of a word in the document = Use **Bernoulli**\n",
    "\n",
    "Explanation on Bernoulli VS Multinomial --> https://medium.com/analytics-vidhya/twitter-sentimental-analysis-using-naive-bayes-classifier-process-explanation-f532b96b30b8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c097da3",
   "metadata": {},
   "source": [
    "## Approach 1: Multinomial Naive Bayes<a name=\"Section13\"></a>\n",
    "\n",
    "It is used when we have discrete data (e.g. tweets ratings ranging 1 and 5 as each rating will have certain frequency to represent). In text classification we have the count of each word to predict the class or label. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cdd4ab",
   "metadata": {},
   "source": [
    "**Training the Naive Bayes Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45cf9311",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.01347661018371582 seconds\n",
      "{'alpha': 1.0, 'class_prior': None, 'fit_prior': True}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ -9.92385861, -10.22150227, -10.22150227, ..., -10.22150227,\n",
       "        -10.22150227, -10.22150227],\n",
       "       [ -9.93046248, -10.32139499, -10.37473344, ..., -10.32457925,\n",
       "        -10.4907963 , -10.47148981],\n",
       "       [-10.02524548, -10.02524548, -10.02524548, ..., -10.02524548,\n",
       "        -10.02524548, -10.02524548],\n",
       "       [-10.21011097,  -9.83728451,  -9.91184149, ..., -10.39136337,\n",
       "        -10.39136337, -10.39136337]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "#Create instance of Naive Bayes classifier (either MultinomialNB or BernoulliNB)\n",
    "mnb_classifier = MultinomialNB()\n",
    "\n",
    "# Train a Naive Bayes classifier on the training data\n",
    "start_time = time.time()\n",
    "mnb_classifier.fit(train_features_vectorized, train_labels)\n",
    "end_time = time.time()\n",
    "\n",
    "# Print the runtime of training the classifier\n",
    "print(f\"Training time: {end_time - start_time} seconds\")\n",
    "print(mnb_classifier.get_params())\n",
    "display(mnb_classifier.feature_log_prob_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae79a6b",
   "metadata": {},
   "source": [
    "**Predict labels of test data**\n",
    "<br>\n",
    "Use the print() function to display the test_predictions array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8182ff17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['Positive', 'Positive', 'Positive', ..., 'Positive', 'Positive',\n",
       "       'Positive'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a list of the sentiment labels\n",
    "sentiment_labels = ['Positive', 'Negative']\n",
    "\n",
    "# Predict the labels of the test data\n",
    "start_time = time.time()\n",
    "test_predictions = mnb_classifier.predict(test_features_vectorized)\n",
    "end_time = time.time()\n",
    "\n",
    "# Convert the numeric labels back to sentiment labels\n",
    "actual_sentiments = encoder.inverse_transform(test_labels)\n",
    "predicted_sentiments = encoder.inverse_transform(test_predictions)\n",
    "\n",
    "# Print the predicted labels\n",
    "display(test_predictions, predicted_sentiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d532ced2",
   "metadata": {},
   "source": [
    "**Print results of predicted labels using DataFrame**\n",
    "\n",
    "Create a new DataFrame that combines the test data with the predicted labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce641cde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>actual_sentiment</th>\n",
       "      <th>predicted_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hungry cook</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>want take responsibility accnt endo getting ne...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>please relax worried know love work please lov...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>annual agenda pansos hurry came path individua...</td>\n",
       "      <td>Mild Negative</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>okay csb worried growing old ouch inner tita g...</td>\n",
       "      <td>Weakly Negative</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6547</th>\n",
       "      <td>according estimate lost wasted could feed bill...</td>\n",
       "      <td>Mild Negative</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6548</th>\n",
       "      <td>worried thai aluminum work leave building resp...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6549</th>\n",
       "      <td>cheap sunny good food gave creature comfort ci...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6550</th>\n",
       "      <td>sodiq rishema hour stomach hungry</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6551</th>\n",
       "      <td>close minute waiting rice wedding rice gone mc...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6552 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text actual_sentiment   \n",
       "0                                           hungry cook         Positive  \\\n",
       "1     want take responsibility accnt endo getting ne...         Positive   \n",
       "2     please relax worried know love work please lov...         Positive   \n",
       "3     annual agenda pansos hurry came path individua...    Mild Negative   \n",
       "4     okay csb worried growing old ouch inner tita g...  Weakly Negative   \n",
       "...                                                 ...              ...   \n",
       "6547  according estimate lost wasted could feed bill...    Mild Negative   \n",
       "6548  worried thai aluminum work leave building resp...         Positive   \n",
       "6549  cheap sunny good food gave creature comfort ci...         Positive   \n",
       "6550                  sodiq rishema hour stomach hungry         Positive   \n",
       "6551  close minute waiting rice wedding rice gone mc...         Positive   \n",
       "\n",
       "     predicted_sentiment  \n",
       "0               Positive  \n",
       "1               Positive  \n",
       "2               Positive  \n",
       "3               Positive  \n",
       "4               Positive  \n",
       "...                  ...  \n",
       "6547            Positive  \n",
       "6548            Positive  \n",
       "6549            Positive  \n",
       "6550            Positive  \n",
       "6551            Positive  \n",
       "\n",
       "[6552 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a DataFrame with the test data and predicted labels\n",
    "results_df = pd.DataFrame({'Text': test_data['Cleaned_Tweets'], 'actual_sentiment': actual_sentiments, \n",
    "                           'predicted_sentiment': predicted_sentiments})\n",
    "\n",
    "# Print the DataFrame\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ba1712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to map sentiment labels to risk labels\n",
    "sentiment_labels = ['Positive', 'Weakly Negative', 'Mild Negative', 'Strongly Negative']\n",
    "risk_labels = ['Low Risk', 'Mild Risk', 'Moderate Risk', 'Severe Risk']\n",
    "label_mapping = {sentiment_labels[i]: risk_labels[i] for i in range(len(sentiment_labels))}\n",
    "\n",
    "# Apply reassignment to the actual and predicted sentiment labels\n",
    "results_df['actual_risk'] = results_df['actual_sentiment'].map(label_mapping)\n",
    "results_df['predicted_risk'] = results_df['predicted_sentiment'].map(label_mapping)\n",
    "\n",
    "# Print the dataframe\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fe18b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save results into CSV file\n",
    "results_df.to_csv('MNB_BOW (80-20)- Predict Label Modelling Results (RS=0)[Harmonized].csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bc01bc",
   "metadata": {},
   "source": [
    "## Approach 2: Bernoulli Naive Bayes<a name=\"Section14\"></a>\n",
    "\n",
    "It assumes that all our features are binary such that they take only two values. \n",
    "\n",
    "Means 0s can represent “word does not occur in the document” and 1s as “word occurs in the document”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d5eaf3",
   "metadata": {},
   "source": [
    "**Training the Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea70b32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "#Create instance of Naive Bayes classifier\n",
    "bnb_classifier = BernoulliNB()\n",
    "\n",
    "# Train a Naive Bayes classifier on the training data\n",
    "start_time = time.time()\n",
    "bnb_classifier.fit(train_features_vectorized, train_labels)\n",
    "end_time = time.time()\n",
    "\n",
    "# Print the runtime of training the classifier\n",
    "print(f\"Training time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e309d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bnb_classifier.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3273280",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(bnb_classifier.feature_log_prob_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152eb1e0",
   "metadata": {},
   "source": [
    "**Predict labels of test data**\n",
    "<br>\n",
    "Use the print() function to display the test_predictions array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363ab853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels of the test data\n",
    "start_time = time.time()\n",
    "test_predictions = bnb_classifier.predict(test_features_vectorized)\n",
    "end_time = time.time()\n",
    "\n",
    "# Print the runtime of predicting the labels\n",
    "print(f\"Prediction time: {end_time - start_time} seconds\")\n",
    "\n",
    "# Print the predicted labels\n",
    "print(test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f35992",
   "metadata": {},
   "source": [
    "**Print results of predicted labels using DataFrame**\n",
    "\n",
    "Create a new DataFrame that combines the test data with the predicted labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a75ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with the test data and predicted labels\n",
    "results_df = pd.DataFrame({'Text': test_data['Cleaned_Tweets'], 'actual_sentiment': test_labels, \n",
    "                           'predicted_sentiment': test_predictions})\n",
    "\n",
    "# Print the DataFrame\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc24a73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save results into CSV file\n",
    "results_df.to_csv('BNB_TF-IDF (70-20)- Predict Label Modelling Results [Harmonized].csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bbe444",
   "metadata": {},
   "source": [
    "## Pickling the Model<a name=\"Section15\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fd7974",
   "metadata": {},
   "source": [
    "If you still want to see the full output of the classifier object, you can try using the pickle module to save the classifier object to a file and then load it back into memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22a763b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the classifier object to a file\n",
    "with open('BNB_classifier TF-IDF (Harmonized-70-30).pkl', 'wb') as file:\n",
    "    pickle.dump(bnb_classifier, file)\n",
    "\n",
    "# Print the classifier object\n",
    "print(bnb_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20341fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the classifier object from the file\n",
    "with open('nb_classifier.pkl', 'rb') as file:\n",
    "    nb_classifier = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c4894d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In case you wanna use the loaded classifier model from file\n",
    "# Use this code to perform prediction\n",
    "predictions = loaded_model.predict(new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91112225",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation<a name=\"Section4\"></a>\n",
    "<br></br>\n",
    "**A. Evaluation Metrics:**\n",
    "\n",
    "1. Accuracy\n",
    "<br></br>\n",
    "2. Precision\n",
    "<br></br>\n",
    "3. F1 Score\n",
    "<br> Due to an imbalance classes, F1 score was metric was used </br>\n",
    "4. Recall\n",
    "\n",
    "**B. K-Fold Cross Validation**\n",
    "\n",
    "Using k-fold (k = 10)\n",
    "<br></br>\n",
    "Part of code retrieved from here:\n",
    "https://github.com/ThinamXx/Twitter..Sentiment..Analysis/blob/master/Twitter%20Sentiment%20Analysis.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b001a1f",
   "metadata": {},
   "source": [
    "<h2> A. Evaluation Metrics </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff30ff4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using the fitted model to make predictions on testing data\n",
    "# Predict the labels of the test data\n",
    "test_predictions = bnb_classifier.predict(test_features_vectorized)\n",
    "\n",
    "# Print the predicted labels\n",
    "print(test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a79e44",
   "metadata": {},
   "source": [
    "**Checking the accuracy in Testing Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94876fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the performance of Naive Bayes classifier\n",
    "\n",
    "print(f\"Model evaluation on Testing Data:\\n {confusion_matrix(test_labels, test_predictions)}\")\n",
    "print(f\"Classification Report:\\n {classification_report(test_labels, test_predictions)}\")\n",
    "print(f\"Testing accuracy:\\n {accuracy_score(test_labels, test_predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5027b939",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(test_labels, test_predictions)\n",
    "\n",
    "# Calculate the precision of the classifier\n",
    "precision = precision_score(test_labels, test_predictions, average='weighted')\n",
    "\n",
    "# Calculate the recall of the classifier\n",
    "recall = recall_score(test_labels, test_predictions, average='weighted')\n",
    "\n",
    "# Calculate the F1 score of the classifier\n",
    "f1 = f1_score(test_labels, test_predictions, average='weighted')\n",
    "\n",
    "# Calculate the confusion matrix of the classifier\n",
    "confusion_mat = confusion_matrix(test_labels, test_predictions)\n",
    "\n",
    "# Define the labels for the confusion matrix\n",
    "labels = ['True Negative (TN)', 'False Positive (FP)', 'False Negative (FN)', 'True Positive (TP)']\n",
    "\n",
    "# Create a new confusion matrix with the labels\n",
    "confusion_mat_labeled = np.empty((2,2), dtype=int)\n",
    "confusion_mat_labeled[0,0] = confusion_mat[0,0] # True Negative\n",
    "confusion_mat_labeled[0,1] = confusion_mat[0,1] # False Positive\n",
    "confusion_mat_labeled[1,0] = confusion_mat[1,0] # False Negative\n",
    "confusion_mat_labeled[1,1] = confusion_mat[1,1] # True Positive\n",
    "\n",
    "# Create a DataFrame with the confusion matrix and labels\n",
    "confusion_df = pd.DataFrame(confusion_mat_labeled, index=labels[:2], columns=labels[2:])\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Evaluation Metrics:\")\n",
    "print(\"Accuracy:\", accuracy * 100, \"%\")\n",
    "print(\"Precision:\", precision * 100, \"%\")\n",
    "print(\"Recall:\", recall * 100, \"%\")\n",
    "print(\"F1 Score:\", f1 * 100, \"%\")\n",
    "display(\"Confusion Matrix:\", confusion_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48adad77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store the evaluation metrics (Initial)\n",
    "evaluation_results = {\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "    'Score': [accuracy, precision, recall, f1]\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the evaluation results\n",
    "df_evaluation = pd.DataFrame(evaluation_results)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix\n",
    "confusion_df = pd.DataFrame(confusion_mat, columns=['False Negative', 'False Positive'], index=['True Negative', 'True Positive'])\n",
    "\n",
    "# Concatenate the evaluation DataFrame and confusion DataFrame\n",
    "results_df = pd.concat([df_evaluation, confusion_df], axis=0)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "results_df.to_csv('[Harmonized] MNB TF-IDF (80-20) Initial Model_Evaluation.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c96d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Harmonized Sentiments Dataset\n",
    "# Create a DataFrame from the confusion matrix\n",
    "confusion_df = pd.DataFrame(confusion_mat, columns=sentiment_labels, index=sentiment_labels)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "results_df.to_csv('[Harmonized] MNB TF-IDF (70-30) Initial Model_Evaluation.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3d6d88",
   "metadata": {},
   "source": [
    "**Error Analysis**\n",
    "\n",
    "In this part, we will see some tweets that your model missclassified. Why do we think the misclassifications happened? Were there any assumptions made by the naive bayes model?\n",
    "\n",
    "Source:\n",
    "<br>\n",
    "https://github.com/cdaman123/Sentiment-Analysis-using-Naive-Bayes/blob/main/Sentiment_Analysis_NB.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3c4306",
   "metadata": {},
   "source": [
    "<h3>ROC Curve</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0981f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the probabilities of the test data\n",
    "test_probabilities = mnb_classifier.predict_proba(test_features_vectorized)[:, 1]\n",
    "\n",
    "# Print the predicted labels\n",
    "print(test_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6089b03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(test_labels, test_probabilities)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae61a105",
   "metadata": {},
   "source": [
    "**HARMONIZED SENTIMENT TWEETS DATASET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47efb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Binarize the test labels\n",
    "binarized_labels = label_binarize(test_labels, classes=[0, 1, 2, 3])\n",
    "\n",
    "# Compute the probability predictions for each class\n",
    "test_probabilities = mnb_classifier.predict_proba(test_features)\n",
    "\n",
    "# Compute the ROC curve and ROC AUC score for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "n_classes = len(sentiment_labels)\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(binarized_labels[:, i], test_probabilities[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC AUC score\n",
    "fpr_micro, tpr_micro, _ = roc_curve(binarized_labels.ravel(), test_probabilities.ravel())\n",
    "roc_auc_micro = auc(fpr_micro, tpr_micro)\n",
    "\n",
    "# Plot ROC curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot micro-average ROC curve\n",
    "plt.plot(fpr_micro, tpr_micro, label='Micro-average ROC curve (area = {0:0.2f})'\n",
    "         ''.format(roc_auc_micro), linestyle=':', linewidth=4)\n",
    "\n",
    "# Plot ROC curve for each class\n",
    "for i in range(n_classes):\n",
    "    plt.plot(fpr[i], tpr[i], label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(sentiment_labels[i], roc_auc[i]), linewidth=2)\n",
    "\n",
    "# Add plot labels and legends\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be39ee0b",
   "metadata": {},
   "source": [
    "<h2> B. K-fold Cross Validation </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff99cd20",
   "metadata": {},
   "source": [
    "Use the cross_val_score() function from sklearn.model_selection to evaluate the performance of the classifier using 5-fold cross-validation. \n",
    "<br></br>\n",
    "The cross_val_score() function takes the classifier, the feature vectors, the labels, and the number of folds as input, and returns an array of scores for each fold\n",
    "\n",
    "**Output: Cross-validation scores for each fold + Average cross-validation score**\n",
    "\n",
    "Note: cv = k (k-fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7ef2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Perform k-fold cross-validation and obtain the scores for each fold\n",
    "scores = cross_val_score(bnb_classifier, train_features_vectorized, train_labels, cv=10)\n",
    "\n",
    "# Print the accuracy for each fold\n",
    "for fold, score in enumerate(scores):\n",
    "    print(f\"Fold {fold+1}: {score}\")\n",
    "\n",
    "# Calculate and print the mean accuracy and standard deviation\n",
    "mean_accuracy = scores.mean()\n",
    "std_deviation = scores.std()\n",
    "print(f\"Mean accuracy: {mean_accuracy}\")\n",
    "print(f\"Standard deviation: {std_deviation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04db2827",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Evaluate the performance of Naive Bayes classifier using cross-validation\n",
    "scores = cross_val_score(bnb_classifier, train_features_vectorized, train_labels, cv=10)\n",
    "\n",
    "# Print the cross-validation scores\n",
    "print(f\"Cross-validation scores: {scores}\")\n",
    "print(f\"Average cross-validation score: {scores.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fe0100",
   "metadata": {},
   "source": [
    "**How to find the BEST hyperparameters for Naive Bayes classifier**\n",
    "\n",
    "The GridSearchCV() function takes the classifier, the hyperparameters, and the number of folds as input, and returns the best hyperparameters and the corresponding score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a59935",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV #Perform grid search over hyperparameters\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "\n",
    "# Create instance of Naive Bayes classifier\n",
    "#mnb_classifier = MultinomialNB()\n",
    "bnb_classifier = BernoulliNB()\n",
    "\n",
    "# Define the hyperparameters to search over\n",
    "hyperparameters = {'alpha': [0.1, 0.5, 1.0, 2.0, 5.0, 10.0]}\n",
    "\n",
    "# Use grid search to find the best hyperparameters for the classifier\n",
    "grid_search = GridSearchCV(bnb_classifier, hyperparameters, cv=10)\n",
    "grid_search.fit(train_features_vectorized, train_labels)\n",
    "\n",
    "# Print the best hyperparameters and the corresponding score\n",
    "print(f\"Best hyperparameters: {grid_search.best_params_}\")\n",
    "print(f\"Best score: {grid_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc55abe",
   "metadata": {},
   "source": [
    "We then print the best hyperparameters and the corresponding score using the print() function. The resulting output will show the best hyperparameters found by the grid search and the corresponding score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c28cbb",
   "metadata": {},
   "source": [
    "After finding the best hyperparameters, you can process to train and evaluate Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01976907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN values with an empty string\n",
    "train_features = np.where(pd.isnull(train_features), '', train_features)\n",
    "\n",
    "# Create an instance of CountVectorizer\n",
    "vectorizer = TfidfVectorizer()  # For TF-IDF\n",
    "#vectorizer = CountVectorizer()  # For BoW\n",
    "\n",
    "# Fit the vectorizer on the training data and transform the training features\n",
    "train_features_vectorized = vectorizer.fit_transform(train_features)\n",
    "\n",
    "# Transform the testing features using the trained vectorizer\n",
    "test_features_vectorized = vectorizer.transform(test_features)\n",
    "\n",
    "train_features_vectorized.shape, test_features_vectorized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065a39a4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# Remember to modify test size each time you're trying to run a new model!!\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, encoded_labels, \n",
    "                                                                            test_size=0.3, random_state=42)\n",
    "\n",
    "# Replace NaN values with an empty string\n",
    "train_features = np.where(pd.isnull(train_features), '', train_features)\n",
    "\n",
    "# Create an instance of CountVectorizer\n",
    "vectorizer = TfidfVectorizer()  # For TF-IDF\n",
    "#vectorizer = CountVectorizer()  # For BoW\n",
    "\n",
    "# Fit the vectorizer on the training data and transform the training features\n",
    "train_features_vectorized = vectorizer.fit_transform(train_features)\n",
    "\n",
    "# Transform the testing features using the trained vectorizer\n",
    "test_features_vectorized = vectorizer.transform(test_features)\n",
    "\n",
    "# Create instance of Naive Bayes classifier with best hyperparameters\n",
    "#mnb_classifier = MultinomialNB(alpha=1.0)\n",
    "bnb_classifier = BernoulliNB(alpha=2.0)\n",
    "\n",
    "# Train a Naive Bayes classifier on the training data\n",
    "bnb_classifier.fit(train_features_vectorized, train_labels)\n",
    "\n",
    "# Predict the labels of the test data\n",
    "test_predictions = bnb_classifier.predict(test_features_vectorized)\n",
    "\n",
    "# Evaluate the performance of the classifier on the test data\n",
    "confusion = confusion_matrix(test_labels, test_predictions)\n",
    "report = classification_report(test_labels, test_predictions)\n",
    "accuracy = accuracy_score(test_labels, test_predictions)\n",
    "\n",
    "# Print the confusion matrix, classification report, and accuracy score\n",
    "print(f\"Confusion matrix:\\n{confusion}\")\n",
    "print(f\"Classification report:\\n{report}\")\n",
    "print(f\"Accuracy score: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a82677",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(test_labels, test_predictions)\n",
    "\n",
    "# Calculate the precision of the classifier\n",
    "precision = precision_score(test_labels, test_predictions, average='weighted')\n",
    "\n",
    "# Calculate the recall of the classifier\n",
    "recall = recall_score(test_labels, test_predictions, average='weighted')\n",
    "\n",
    "# Calculate the F1 score of the classifier\n",
    "f1 = f1_score(test_labels, test_predictions, average='weighted')\n",
    "\n",
    "# Calculate the confusion matrix of the classifier\n",
    "confusion_mat = confusion_matrix(test_labels, test_predictions)\n",
    "\n",
    "# Define the labels for the confusion matrix\n",
    "labels = ['True Negative (TN)', 'False Positive (FP)', 'False Negative (FN)', 'True Positive (TP)']\n",
    "\n",
    "# Create a new confusion matrix with the labels\n",
    "confusion_mat_labeled = np.empty((2,2), dtype=int)\n",
    "confusion_mat_labeled[0,0] = confusion_mat[0,0] # True Negative\n",
    "confusion_mat_labeled[0,1] = confusion_mat[0,1] # False Positive\n",
    "confusion_mat_labeled[1,0] = confusion_mat[1,0] # False Negative\n",
    "confusion_mat_labeled[1,1] = confusion_mat[1,1] # True Positive\n",
    "\n",
    "# Create a DataFrame with the confusion matrix and labels\n",
    "confusion_df = pd.DataFrame(confusion_mat_labeled, index=labels[:2], columns=labels[2:])\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Evaluation Metrics:\")\n",
    "print(\"Accuracy:\", accuracy * 100, \"%\")\n",
    "print(\"Precision:\", precision * 100, \"%\")\n",
    "print(\"Recall:\", recall * 100, \"%\")\n",
    "print(\"F1 Score:\", f1 * 100, \"%\")\n",
    "display(\"Confusion Matrix:\", confusion_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2827ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store the evaluation metrics (After tuning)\n",
    "evaluation_results = {\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "    'Score': [accuracy, precision, recall, f1]\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the evaluation results\n",
    "df_evaluation = pd.DataFrame(evaluation_results)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix\n",
    "confusion_df = pd.DataFrame(confusion_mat, columns=['False Negative', 'False Positive'], index=['True Negative', 'True Positive'])\n",
    "\n",
    "# Concatenate the evaluation DataFrame and confusion DataFrame\n",
    "results_df = pd.concat([df_evaluation, confusion_df], axis=0)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "results_df.to_csv('[Harmonized] MNB BOW (80-20) Post Hypertuning Model_Evaluation.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b3c14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Harmonized Sentiments Dataset\n",
    "# Create a DataFrame from the confusion matrix\n",
    "confusion_df = pd.DataFrame(confusion_mat, columns=sentiment_labels, index=sentiment_labels)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "results_df.to_csv('[Harmonized] MNB TF-IDF (80-20) Post Hypertuning Model_Evaluation.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c009730c",
   "metadata": {},
   "source": [
    "## 5. Predict Sentiment of New text Data<a name=\"Section5\"></a>\n",
    "Back to [Top Page](#TOC)\n",
    "\n",
    "Using the trained model classifier, we can predict the sentiment of new text data\n",
    "<br>\n",
    "\n",
    "Positive [1] - Food Secured\n",
    "\n",
    "Negative [0] - Food Insecure\n",
    "\n",
    "A) [VADER/TextBlob Dataset](#Section14)\n",
    "<br>\n",
    "B) [Harmonized Dataset](#Section15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f4ee62",
   "metadata": {},
   "source": [
    "### A) VADER/TextBlob Dataset<a name=\"Section14\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e051c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Create an instance of TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()  # For TF-IDF\n",
    "\n",
    "# Create a CountVectorizer object\n",
    "#vectorizer = CountVectorizer() # For BOW\n",
    "\n",
    "# Vectorize the training data\n",
    "features_vectorized = vectorizer.fit_transform(train_features)\n",
    "\n",
    "# Create instance of Naive Bayes classifier with best hyperparameters\n",
    "#mnb_classifier = MultinomialNB(alpha=1.0)\n",
    "bnb_classifier = BernoulliNB(alpha=2.0)\n",
    "\n",
    "# Train a Naive Bayes classifier on the training data\n",
    "bnb_classifier.fit(train_features_vectorized, train_labels)\n",
    "\n",
    "# Predict the sentiment of new text data\n",
    "new_data = [\"I'm so angry about the high food prices! It's making it so hard for me to feed my family.\",\n",
    "            \"I'm so grateful for the food banks and other organizations that are helping to feed people who are struggling. They're making a real difference.\",\n",
    "            \"I'm so worried about the future of food security. Climate change is making it harder to grow food, and more people are going hungry.\",\n",
    "            \"I'm so inspired by the work of food banks and other organizations that are fighting hunger. They're making a real difference in people's lives.\",\n",
    "            \"I'm hopeful that we can create a world where everyone has access to the food they need to live a healthy and productive life\",\n",
    "            \"I'm working part-time and I'm not sure if I'll be able to keep my job.\",\n",
    "            \"I'm not sure if I'll be able to afford to pay my rent this month.\"\n",
    "           ]\n",
    "\n",
    "new_data_vectorized = vectorizer.transform(new_data)\n",
    "new_data_predictions = bnb_classifier.predict(new_data_vectorized)\n",
    "new_data_sentiment_scores = bnb_classifier.predict_proba(new_data_vectorized)[:, 1]  # Positive sentiment score\n",
    "\n",
    "# Print the predicted sentiment + sentiment scoures for the new data\n",
    "for i in range(len(new_data)):\n",
    "    print(f\"Text: {new_data[i]}\")\n",
    "    sentiment_label = \"Food Secured\" if new_data_predictions[i] == 1 else \"Food Insecure\"\n",
    "    print(f\"Predicted sentiment: {sentiment_label}\")\n",
    "    print(f\"Sentiment score: {new_data_sentiment_scores[i]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5715af83",
   "metadata": {},
   "source": [
    "**Save the new data results into CSV file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f1c581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame to store the results\n",
    "results_df = pd.DataFrame({\n",
    "    'Text': new_data,\n",
    "    'Predicted Sentiment': new_data_predictions,\n",
    "    'Sentiment Score': new_data_sentiment_scores\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "results_df.to_csv('[SAMPLE] [BNB] TF-IDF Harmonized (70-30) new_data_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1fd0db",
   "metadata": {},
   "source": [
    "### B) Harmonized Dataset<a name=\"Section15\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1306bc94",
   "metadata": {},
   "source": [
    "**Predict sentiment & FI Risk Category of New Text Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267d59cb",
   "metadata": {},
   "source": [
    "### Immediate Solution for Predicting FI Risk <a name=\"Section16\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5696851",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define the risk category mapping\n",
    "risk_category_mapping = {\n",
    "    0: \"\\033[1;32mLow Risk\\033[0m\",  # Green\n",
    "    1: \"\\033[1;33mMild Risk\\033[0m\", # Yellow\n",
    "    2: \"\\033[1;31mModerate Risk\\033[0m\", # Orange\n",
    "    3: \"\\033[1;31mSevere Risk\\033[0m\"  # Red\n",
    "}\n",
    "\n",
    "# Create a CountVectorizer object\n",
    "vectorizer = TfidfVectorizer() # For TF-IDF\n",
    "#vectorizer = CountVectorizer() # For BOW\n",
    "\n",
    "# Vectorize the training data\n",
    "features_vectorized = vectorizer.fit_transform(train_features)\n",
    "\n",
    "#Create an instance for hypertuned Naive Baise Classifier\n",
    "#mnb_classifier = MultinomialNB(alpha=1.0)\n",
    "bnb_classifier = BernoulliNB(alpha=2.0)\n",
    "\n",
    "# Train a Multinomial Logistic Regression classifier on the training data\n",
    "bnb_classifier.fit(train_features_vectorized, train_labels)\n",
    "\n",
    "# Function to predict sentiment, sentiment score, and FI risk category of new text data\n",
    "def predict_sentiment_and_fi_risk(text):\n",
    "    # Vectorize the new text data\n",
    "    new_text_vectorized = vectorizer.transform([text])\n",
    "\n",
    "    # Predict the sentiment using the trained model\n",
    "    sentiment = bnb_classifier.predict(new_text_vectorized)[0]\n",
    "\n",
    "    # Predict the sentiment score using the trained model\n",
    "    sentiment_score = np.max(bnb_classifier.predict_proba(new_text_vectorized))\n",
    "\n",
    "    # Assign the FI risk category based on sentiment and sentiment score\n",
    "    if sentiment == 1:  # Positive sentiment (Food Secured)\n",
    "        fi_sentiment = \"Positive\"\n",
    "        fi_risk = risk_category_mapping[0]  # Low Risk\n",
    "    else:  # Negative sentiment\n",
    "        sentiment_score *= -1  # Multiply the sentiment score by -1 for Negative sentiment (Food Insecure)\n",
    "        \n",
    "        if (sentiment_score > -1.0) and (sentiment_score <= -0.6):\n",
    "            fi_sentiment = \"Negative (Strongly Negative)\"\n",
    "            fi_risk = risk_category_mapping[3]  # Severe Risk\n",
    "        elif (sentiment_score > -0.6) and (sentiment_score <= -0.3):\n",
    "            fi_sentiment = \"Negative (Mild Negative)\"\n",
    "            fi_risk = risk_category_mapping[2]  # Moderate Risk\n",
    "        else:\n",
    "            fi_sentiment = \"Negative (Weakly Negative)\"\n",
    "            fi_risk = risk_category_mapping[1]  # Mild Risk\n",
    "\n",
    "    return fi_sentiment, sentiment_score, fi_risk\n",
    "\n",
    "\n",
    "# Predict the sentiment, sentiment score, and FI risk for the new text data\n",
    "new_data = [\n",
    "    \"I'm so angry about the high food prices! It's making it so hard for me to feed my family.\",\n",
    "    \"I'm so grateful for the food banks and other organizations that are helping to feed people who are struggling. They're making a real difference.\",\n",
    "    \"I'm so worried about the future of food security. Climate change is making it harder to grow food, and more people are going hungry.\",\n",
    "    \"I'm so inspired by the work of food banks and other organizations that are fighting hunger. They're making a real difference in people's lives.\",\n",
    "    \"I'm hopeful that we can create a world where everyone has access to the food they need to live a healthy and productive life\",\n",
    "    \"I'm working part-time and I'm not sure if I'll be able to keep my job.\",\n",
    "    \"I'm not sure if I'll be able to afford to pay my rent this month.\"\n",
    "]\n",
    "\n",
    "final_results = []\n",
    "for text in new_data:\n",
    "    fi_sentiment, sentiment_score, fi_risk = predict_sentiment_and_fi_risk(text)\n",
    "    print(\"Text:\", text)\n",
    "    print(\"Predicted sentiment:\", fi_sentiment)\n",
    "    print(\"Sentiment score:\", sentiment_score)\n",
    "    print(\"FI Risk:\", fi_risk)\n",
    "    print()\n",
    "    \n",
    "    # Store the results in a dictionary\n",
    "    final_result = {\n",
    "        \"Text\": text,\n",
    "        \"Predicted Sentiment\": fi_sentiment,\n",
    "        \"Sentiment Score\": sentiment_score,\n",
    "        \"FI Risk\": fi_risk\n",
    "    }\n",
    "    final_results.append(final_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031ee55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for the results\n",
    "final_results_df = pd.DataFrame(final_results)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(final_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa135a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "final_results_df.to_csv('[SAMPLE] [BNB] TF-IDF Harmonized (70-30) final new_data_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae09582",
   "metadata": {},
   "source": [
    "### ALTERNATE 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f13e52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "    if sentiment_score > 0 and sentiment_score <= 1.0:\n",
    "        sentiment_label = \"Positive - Food Secured\"\n",
    "        fi_risk_category = \"\\033[1;32mLow\\033[0m\"  # Green\n",
    "    elif sentiment_score > -0.3 and sentiment_score <= 0:\n",
    "        sentiment_label = \"Negative - Food Insecure\"\n",
    "        fi_risk_category = \"\\033[1;33mMild\\033[0m\" # Yellow\n",
    "    elif sentiment_score > -0.6 and sentiment_score <= -0.3:\n",
    "        sentiment_label = \"Negative - Food Insecure\"\n",
    "        fi_risk_category = \"\\033[1;31mModerate\\033[0m\" # Orange\n",
    "    elif sentiment_score > -1.0 and sentiment_score <= -0.6:\n",
    "        sentiment_label = \"Negative - Food Insecure\"\n",
    "        fi_risk_category = \"\\033[1;31mSevere\\033[0m\"  # Red\n",
    "    else:\n",
    "        sentiment_label = \"Invalid Sentiment & No FI Risk\"\n",
    "        fi_risk_category = \"Invalid FI Risk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b19807",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define the risk category mapping\n",
    "risk_category_mapping = {\n",
    "    0: \"\\033[1;32mLow Risk\\033[0m\",  # Green\n",
    "    1: \"\\033[1;33mMild Risk\\033[0m\", # Yellow\n",
    "    2: \"\\033[1;31mModerate Risk\\033[0m\", # Orange\n",
    "    3: \"\\033[1;31mSevere Risk\\033[0m\"  # Red\n",
    "}\n",
    "\n",
    "# Function to predict sentiment, sentiment score, and FI risk category of new text data\n",
    "def predict_sentiment_and_fi_risk(text):\n",
    "    # Vectorize the new text data\n",
    "    new_text_vectorized = vectorizer.transform([text])\n",
    "\n",
    "    # Predict the sentiment using the trained model\n",
    "    sentiment = mnb_classifier.predict(new_text_vectorized)[0]\n",
    "\n",
    "    # Predict the sentiment score using the trained model\n",
    "    sentiment_score = np.max(mnb_classifier.predict_proba(new_text_vectorized))\n",
    "\n",
    "    # Assign the FI risk category based on sentiment and sentiment score\n",
    "    if sentiment == 1:  # Positive sentiment (Food Secured)\n",
    "        fi_sentiment = \"Positive\"\n",
    "        fi_risk = risk_category_mapping[0]  # Low Risk\n",
    "    else:  # Negative sentiment\n",
    "        sentiment_score *= -1  # Multiply the sentiment score by -1 for Negative sentiment (Food Insecure)\n",
    "        \n",
    "        if (sentiment_score > -1.0) and (sentiment_score <= -0.6):\n",
    "            fi_sentiment = \"Negative (Strongly Negative)\"\n",
    "            fi_risk = risk_category_mapping[3]  # Severe Risk\n",
    "        elif (sentiment_score > -0.6) and (sentiment_score <= -0.3):\n",
    "            fi_sentiment = \"Negative (Mild Negative)\"\n",
    "            fi_risk = risk_category_mapping[2]  # Moderate Risk\n",
    "        else:\n",
    "            fi_sentiment = \"Negative (Weakly Negative)\"\n",
    "            fi_risk = risk_category_mapping[1]  # Mild Risk\n",
    "\n",
    "    return fi_sentiment, sentiment_score, fi_risk\n",
    "\n",
    "\n",
    "# Predict the sentiment, sentiment score, and FI risk for the new text data\n",
    "new_data = [\n",
    "    \"I'm so angry about the high food prices! It's making it so hard for me to feed my family.\",\n",
    "    \"I'm so grateful for the food banks and other organizations that are helping to feed people who are struggling. They're making a real difference.\",\n",
    "    \"I'm so worried about the future of food security. Climate change is making it harder to grow food, and more people are going hungry.\",\n",
    "    \"I'm so inspired by the work of food banks and other organizations that are fighting hunger. They're making a real difference in people's lives.\",\n",
    "    \"I'm hopeful that we can create a world where everyone has access to the food they need to live a healthy and productive life\",\n",
    "    \"I'm working part-time and I'm not sure if I'll be able to keep my job.\",\n",
    "    \"I'm not sure if I'll be able to afford to pay my rent this month.\"\n",
    "]\n",
    "\n",
    "for text in new_data:\n",
    "    fi_sentiment, sentiment_score, fi_risk = predict_sentiment_and_fi_risk(text)\n",
    "    print(\"Text:\", text)\n",
    "    print(\"Predicted sentiment:\", fi_sentiment)\n",
    "    print(\"Sentiment score:\", sentiment_score)\n",
    "    print(\"FI Risk:\", fi_risk)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d72d5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "results_df.to_csv('[SAMPLE] [MNB] TF-IDF Harmonized (80-20) final_data_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60661af6",
   "metadata": {},
   "source": [
    "### Alternate 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e46813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BACKUP CODE - Use when NEEDED ONLY!! \n",
    "\n",
    "# Define a function to assign the FI risk category based on the sentiment score\n",
    "def assign_fi_risk(sentiment, score):\n",
    "    if sentiment == 0:\n",
    "        # Assigns Moderate FI risk for negative sentiment score range\n",
    "        if -0.59 <= score < -0.4:\n",
    "            return \"\\033[1;31mModerate\\033[0m\"  # Light Orange\n",
    "        # Assign Severe FI risk for negative sentiment score below -0.6\n",
    "        elif score > -0.6:\n",
    "            return \"\\033[1;31mSevere\\033[0m\"  # Red\n",
    "        else:\n",
    "            # Assigns Mild risk for negative sentiment score range\n",
    "            return \"\\033[1;33mMild\\033[0m\"  # Yellow \n",
    "    elif sentiment == 1:\n",
    "        # Assigns Low FI risk for positive sentiment score range\n",
    "        if 0.1 <= score <= 1:\n",
    "            return \"\\033[1;32mLow\\033[0m\"  # Green\n",
    "        else:\n",
    "            # Invalid sentiment score range\n",
    "            return \"Invalid FI Risk\" \n",
    "    else:\n",
    "        return \"Invalid FI Risk\"  # Invalid sentiment value\n",
    "\n",
    "# Create an empty list to store the results\n",
    "results = []\n",
    "\n",
    "# Print the predicted sentiment + sentiment scores for the new data\n",
    "for i in range(len(new_data)):\n",
    "    print(f\"Text: {new_data[i]}\")\n",
    "    sentiment_label = \"Food Secured\" if new_data_predictions[i] == 1 else \"Food Insecure\"\n",
    "    print(f\"Predicted sentiment: {sentiment_label}\")\n",
    "    sentiment_score = new_data_sentiment_scores[i]\n",
    "    fi_risk = assign_fi_risk(new_data_predictions[i], sentiment_score)\n",
    "    print(f\"Sentiment score: {sentiment_score}\")\n",
    "    print(f\"FI Risk: {fi_risk}\")\n",
    "    print()\n",
    "    \n",
    "    # Append the results to the list\n",
    "    results.append([new_data[i], sentiment_label, sentiment_score, fi_risk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f06a56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pandas dataframe from the results list\n",
    "results_df = pd.DataFrame(results, columns=[\"Text\", \"Sentiment Label\", \"Sentiment Score\", \"FI Risk\"])\n",
    "\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0252406e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "results_df.to_csv('[SAMPLE] [BNB] TF-IDF VADER (80-20) final new_data_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2499db",
   "metadata": {},
   "source": [
    "## 5. Visualization<a name=\"Section5\"></a>\n",
    "\n",
    "**Type of Visualizations:**\n",
    "1. Heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6181db3",
   "metadata": {},
   "source": [
    "**Heatmap**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7131c1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Plotting the heatmap of confusion matrix\n",
    "cm = confusion_matrix(test_labels, test_predictions)\n",
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b7d97d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Define the labels for the confusion matrix\n",
    "labels = ['True Negative', 'False Positive', 'False Negative', 'True Positive']\n",
    "\n",
    "# Create a new confusion matrix with the labels\n",
    "confusion_mat_labeled = np.empty((2,2), dtype=int)\n",
    "confusion_mat_labeled[0,0] = confusion_mat[0,0] # True Negative\n",
    "confusion_mat_labeled[0,1] = confusion_mat[0,1] # False Positive\n",
    "confusion_mat_labeled[1,0] = confusion_mat[1,0] # False Negative\n",
    "confusion_mat_labeled[1,1] = confusion_mat[1,1] # True Positive\n",
    "\n",
    "# Create a DataFrame with the confusion matrix and labels\n",
    "confusion_df = pd.DataFrame(confusion_mat_labeled, index=labels[:2], columns=labels[2:])\n",
    "\n",
    "# Create a heatmap of the confusion matrix\n",
    "sns.heatmap(confusion_df, annot=True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0dce7f",
   "metadata": {},
   "source": [
    "**For Harmonized Sentiment Tweets Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8779db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Perform predictions on the test data\n",
    "test_predictions = bnb_classifier.predict(test_features_vectorized)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "confusion_mat = confusion_matrix(test_labels, test_predictions)\n",
    "\n",
    "# Create a list of sentiment labels\n",
    "sentiment_labels = [\"0\", \"1\", \"2\", \"3\"]\n",
    "\n",
    "# Create a heatmap of the confusion matrix\n",
    "sns.heatmap(confusion_mat, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=sentiment_labels, yticklabels=sentiment_labels)\n",
    "\n",
    "# Set the axis labels and title\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
